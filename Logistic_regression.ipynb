{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0866c-fbb6-4f2b-bb3f-da9644e80dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theoritical\n",
    "#Question1.What is Logistic Regression, and how does it differ from Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb4947-60ee-49a4-8ee5-4843908c6191",
   "metadata": {},
   "source": [
    "Answer\n",
    "Logistic Regression:\n",
    "Purpose: Used for binary classification problems, where the outcome is categorical with two classes (e.g., Yes/No, 0/1, True/False). It's used to predict the probability of a certain class or event occurring.\n",
    "\n",
    "Output: The output of logistic regression is a probability score between 0 and 1. This score can be interpreted as the probability of a data point belonging to a particular class (typically, class 1).\n",
    "\n",
    "Model Form: The model uses the logistic function (also called the sigmoid function), which maps any real-valued number into the range (0, 1).\n",
    "\n",
    "Linear Regression:\n",
    "Purpose: Used for regression problems, where the goal is to predict a continuous value (e.g., predicting house prices, stock prices, temperature).\n",
    "\n",
    "Output: The output of linear regression is a continuous value, which can range from negative infinity to positive infinity.\n",
    "\n",
    "Model Form: The model is based on the linear relationship between the independent variables and the dependent variable.\n",
    "\n",
    "Key Differences:\n",
    "\n",
    "Type of Problem:\n",
    "Logistic Regression: Used for classification (binary output).\n",
    "Linear Regression: Used for regression (continuous output).\n",
    "\n",
    "Output:\n",
    "Logistic Regression: Outputs a probability (between 0 and 1).\n",
    "Linear Regression: Outputs a continuous value (which can be any real number).\n",
    "\n",
    "Equation:\n",
    "Logistic Regression: Uses the logistic/sigmoid function to ensure the output is between 0 and 1.\n",
    "Linear Regression: Uses a linear equation to model the relationship between input features and the output.\n",
    "\n",
    "Error Metrics:\n",
    "Logistic Regression: Typically uses metrics like log-loss or cross-entropy.\n",
    "Linear Regression: Uses metrics like mean squared error (MSE) or R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14adcb2-66cb-4326-abce-800f8f7df7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question2. What is the mathematical equation of Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8cecc-8d30-4651-b458-0d21bf4d0a63",
   "metadata": {},
   "source": [
    "Answer\n",
    "The mathematical equation for Logistic Regression involves the use of the logistic (sigmoid) function to map a linear combination of input features to a probability between 0 and 1.\n",
    "\n",
    "Logistic Regression Equation\n",
    "The general form of the logistic regression equation is:\n",
    "\n",
    "ð‘ƒ(ð‘¦=1âˆ£ð‘‹) = 1/1+ð‘’âˆ’(ð‘0+ð‘1ð‘‹1+ð‘2ð‘‹2+â‹¯+ð‘ð‘›ð‘‹ð‘›)\n",
    "Where:\n",
    "\n",
    "P(y=1âˆ£X) is the probability that the output y is 1 (positive class) given the input features X.\n",
    "b0 is the intercept (bias term).\n",
    "ð‘1,ð‘2,â€¦,ð‘ð‘›are the coefficients (weights) associated with the input features X1 ,X2 ,â€¦,Xn\n",
    "X1 ,X2 ,â€¦,Xn  are the input features (predictor variables).\n",
    "e is the base of the natural logarithm (approximately 2.718)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a949f-6467-4e0f-b46f-4d157aa53d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question3. C Why do we use the Sigmoid function in Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09943dae-1462-4b70-b391-122ba81557bf",
   "metadata": {},
   "source": [
    "Answer\n",
    "the sigmoid function is used in logistic regression because:\n",
    "\n",
    "It transforms the linear output into a valid probability between 0 and 1.\n",
    "It introduces non-linearity, allowing the model to capture complex patterns.\n",
    "It enables interpretation in terms of odds, making it suitable for classification problems.\n",
    "It is smooth and differentiable, making it suitable for optimization.\n",
    "Its saturating behavior helps avoid extreme and unrealistic predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f516c7-e973-4c69-9c93-1057e1da2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question4.What is the cost function of Logistic Regression."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e8cc59e-0550-430e-97d6-82d976708b8d",
   "metadata": {},
   "source": [
    "Answer\n",
    "The cost function for logistic regression is the binary cross-entropy (log-loss) function, which is designed to measure the difference between the true labels and the predicted probabilities. The goal is to minimize this cost function during training by adjusting the model's parameters (weights) through optimization techniques like gradient descent. The cost function ensures that the model produces accurate probability predictions for the binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b9eb6-639b-4ffb-8504-d96880ce2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question5.C What is Regularization in Logistic Regression? Why is it needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631260c0-fd3e-41c1-8650-95fadc13e7ef",
   "metadata": {},
   "source": [
    "Answer\n",
    "Regularization is a technique used in logistic regression to prevent overfitting by adding a penalty term to the cost function. It works by discouraging overly large model parameters (coefficients), leading to simpler and more generalizable models. The two most common types of regularization are L2 regularization (Ridge) and L1 regularization (Lasso), each with its benefits. Regularization is needed to ensure that the model generalizes well to new, unseen data and doesn't simply memorize the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f152bf-3c4a-4089-a378-473e46793b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question6.C Explain the difference between Lasso, Ridge, and Elastic Net regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c482459-fb0f-4363-a84e-6548f670a183",
   "metadata": {},
   "source": [
    "Answer\n",
    "Ridge (L2) is used when you want to shrink coefficients to prevent large weights but donâ€™t necessarily want to eliminate any features. It works well when you believe all features are somewhat important.\n",
    "Lasso (L1) is used when you want to perform feature selection by eliminating irrelevant features. It works well when you suspect many features are irrelevant and want to keep the model simple.\n",
    "Elastic Net is a combination of both Lasso and Ridge regularization, making it ideal when you have correlated features and want to balance between feature selection and shrinkage. It provides the flexibility of both L1 and L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46c432-96b4-431c-9034-becbf542934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question7.When should we use Elastic Net instead of Lasso or Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb15384f-352e-43b6-ae2b-6c208b37cf15",
   "metadata": {},
   "source": [
    "Answer\n",
    " Use Elastic Net Instead of Lasso or Ridge\n",
    " \n",
    "1.When You Have Highly Correlated Features:\n",
    "Problem with Lasso: Lasso tends to select only one feature from a group of highly correlated features and set the others to zero. This is because Lasso applies an L1 penalty, which encourages sparsity and often leads to a situation where only one feature from a correlated group is selected, while others are discarded.\n",
    "\n",
    "Elastic Net Solution: Elastic Net can handle highly correlated features better because it combines both L1 and L2 penalties. The L2 part of Elastic Net allows the model to shrink the coefficients of correlated features together, rather than selecting just one and discarding the others. This helps maintain a balance between feature selection and regularization.\n",
    "\n",
    "When to choose Elastic Net: If your dataset contains many correlated features and you want to retain some of them while also performing regularization, Elastic Net is a better choice.\n",
    "\n",
    "2.When You Have More Features Than Samples (High-Dimensional Data):\n",
    "Problem with Ridge: Ridge tends to work well when the number of features is smaller than the number of observations. However, when you have more features than samples (i.e., a high-dimensional dataset), Ridge may not perform well at feature selection because it shrinks all coefficients but doesn't eliminate them.\n",
    "\n",
    "Problem with Lasso: Lasso can perform feature selection, but when there are more features than samples, it may struggle to provide stable solutions because it can overfit the data.\n",
    "\n",
    "Elastic Net Solution: Elastic Net combines the benefits of L1 regularization (feature selection) and L2 regularization (shrinkage) and is more robust when dealing with high-dimensional data. It can handle situations where the number of features exceeds the number of observations by performing both regularization and feature selection more effectively.\n",
    "\n",
    "When to choose Elastic Net: If you have a high-dimensional dataset (more features than samples), Elastic Net can provide a better balance between feature selection and regularization, ensuring the model doesn't overfit.\n",
    "\n",
    "3.When You Need to Balance Feature Selection and Regularization:\n",
    "Lasso performs aggressive feature selection, potentially setting coefficients to zero for many features. This is useful when you believe that only a few features are important.\n",
    "\n",
    "Ridge performs shrinkage of coefficients but does not set them to zero, which is useful when you believe all features have some predictive power, but you want to shrink their magnitudes to prevent overfitting.\n",
    "\n",
    "Elastic Net Solution: Elastic Net provides a balance between Lasso and Ridge. It performs both feature selection (like Lasso) and shrinkage (like Ridge), making it more flexible when youâ€™re not sure whether to keep all features or just a few important ones.\n",
    "\n",
    "When to choose Elastic Net: If you want a mix of feature selection (removing irrelevant features) and shrinkage (to avoid overfitting), and you're unsure whether Lasso or Ridge would be better, Elastic Net is a good option.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f172799-e6fd-4ab5-a26d-629af2350fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question8.What is the impact of the regularization parameter (Î») in Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55bd66d-2260-435b-b975-d650879c8a9a",
   "metadata": {},
   "source": [
    "Answer\n",
    "Î»=0: No regularization. The model may overfit.\n",
    "Small Î»: Mild regularization. The model is more likely to fit the data well without overfitting, but still may be prone to it.\n",
    "Large Î»: Strong regularization. The model becomes simpler, reducing the risk of overfitting, but can lead to underfitting if Î» is too large.\n",
    "The optimal Î» is typically selected using cross-validation, which minimizes generalization error and avoids both overfitting and underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3f7a7-fd75-4868-af44-661064a2b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question9.What are the key assumptions of Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa9d22-1dbf-4a48-83e8-4c566e18c70b",
   "metadata": {},
   "source": [
    "Answer\n",
    "Key Assumptions of logistics regression\n",
    "1.Binary Outcome: The dependent variable should be binary (two categories).\n",
    "2.Independence of Observations: Observations should be independent of each other.\n",
    "3.Linearity of Log-Odds: The relationship between the predictors and the log-odds of the outcome should be linear.\n",
    "4.No Multicollinearity: Independent variables should not be highly correlated.\n",
    "5.Sufficient Sample Size: A sufficient number of data points are required to estimate model parameters reliably.\n",
    "6.No Strong Outliers: The data should not have extreme outliers that disproportionately affect the model.\n",
    "7.Homoscedasticity: While not a strict assumption in logistic regression, it is still good practice to check for constant variance of errors.\n",
    "8.Correct Model Specification: The model should be correctly specified, with relevant predictors included and proper transformations if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51c912-77bb-4990-8c21-4bdbad1fa405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question10.What are some alternatives to Logistic Regression for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a792613-1994-4981-a078-80a2c1b427f6",
   "metadata": {},
   "source": [
    "Answer\n",
    "1.Decision Trees\n",
    "Description: Decision Trees are a non-linear classification model that splits the data into distinct regions based on feature values. The tree is built by recursively partitioning the data into subsets based on the feature that results in the best split (e.g., using Gini impurity or Information Gain).\n",
    "Advantages:\n",
    "Easy to understand and interpret.\n",
    "Can handle both numerical and categorical features.\n",
    "Can model non-linear relationships.\n",
    "Disadvantages:\n",
    "Prone to overfitting, especially with deep trees.\n",
    "Sensitive to small changes in the data.\n",
    "Unstable unless pruned.\n",
    "When to use: When you need an interpretable model, and there is a non-linear relationship between features and the target variable.\n",
    "\n",
    "2. Random Forest\n",
    "Description: Random Forest is an ensemble learning method that combines multiple Decision Trees to improve classification accuracy. Each tree is trained on a random subset of the data, and the final classification is determined by a majority vote from all the trees.\n",
    "Advantages:\n",
    "Reduces overfitting compared to individual Decision Trees.\n",
    "Handles large datasets well.\n",
    "Works well with both categorical and continuous variables.\n",
    "Disadvantages:\n",
    "Less interpretable than a single Decision Tree.\n",
    "Can be computationally expensive and slower to train.\n",
    "When to use: When you need an accurate model and can sacrifice interpretability, and when you have a large dataset.\n",
    "\n",
    "3. Support Vector Machines (SVM)\n",
    "Description: Support Vector Machines are powerful classifiers that work by finding the hyperplane that best separates the data points of different classes in a high-dimensional space. It uses kernel functions to handle non-linear boundaries.\n",
    "Advantages:\n",
    "Can handle high-dimensional data well.\n",
    "Effective in cases of non-linear decision boundaries (with kernel trick).\n",
    "Robust to overfitting, especially in high-dimensional spaces.\n",
    "Disadvantages:\n",
    "Computationally expensive, especially for large datasets.\n",
    "Sensitive to the choice of kernel and hyperparameters.\n",
    "Less interpretable than Decision Trees.\n",
    "When to use: When the data is high-dimensional or when you need a model that can handle non-linear decision boundaries.\n",
    "\n",
    "4. k-Nearest Neighbors (k-NN)\n",
    "Description: k-NN is a simple, instance-based learning algorithm that classifies a new point based on the majority class of its k nearest neighbors in the feature space.\n",
    "Advantages:\n",
    "Simple to understand and implement.\n",
    "No training phase (instance-based).\n",
    "Can handle multi-class problems easily.\n",
    "Disadvantages:\n",
    "Computationally expensive during prediction (slow for large datasets).\n",
    "Sensitive to the choice of distance metric (e.g., Euclidean).\n",
    "Struggles with high-dimensional data (curse of dimensionality).\n",
    "When to use: When you need a simple model and your dataset is small to medium-sized.\n",
    "\n",
    "5. Naive Bayes\n",
    "Description: Naive Bayes is a family of probabilistic classifiers based on Bayes' Theorem. It assumes that features are conditionally independent given the class label (this assumption is often violated in practice but still works well in many cases).\n",
    "Advantages:\n",
    "Very fast, even for large datasets.\n",
    "Works well with high-dimensional data (e.g., text classification).\n",
    "Can handle both binary and multi-class classification problems.\n",
    "Disadvantages:\n",
    "Assumes independence between features, which is often unrealistic.\n",
    "Performance may suffer when the assumption of independence is violated.\n",
    "When to use: When you have high-dimensional data, like text data, and need a fast and efficient model.\n",
    "\n",
    "6. Gradient Boosting Machines (GBM)\n",
    "Description: Gradient Boosting is an ensemble technique that builds models sequentially by training new models to correct the errors made by previous ones. It can be applied to Decision Trees or other base learners.\n",
    "Advantages:\n",
    "Often produces very accurate models.\n",
    "Can handle complex relationships and interactions between features.\n",
    "Robust to overfitting with proper regularization.\n",
    "Disadvantages:\n",
    "Computationally expensive and slow to train.\n",
    "Requires careful tuning of hyperparameters.\n",
    "When to use: When you need a high-accuracy model and are willing to invest in hyperparameter tuning and computational resources.\n",
    "\n",
    "7. XGBoost (Extreme Gradient Boosting)\n",
    "Description: XGBoost is an optimized and efficient implementation of Gradient Boosting that is widely used in data science competitions. It includes regularization techniques to reduce overfitting and improve generalization.\n",
    "Advantages:\n",
    "Very fast and efficient, especially with large datasets.\n",
    "Includes regularization, making it less prone to overfitting.\n",
    "Highly scalable and widely used in industry.\n",
    "Disadvantages:\n",
    "Requires tuning and careful cross-validation.\n",
    "Complex and less interpretable.\n",
    "When to use: When you need high performance and efficiency, especially on large datasets or in competitions.\n",
    "\n",
    "8. LightGBM (Light Gradient Boosting Machine)\n",
    "Description: LightGBM is another gradient boosting framework that is optimized for efficiency and speed. It is designed to handle large datasets and works well with categorical features.\n",
    "Advantages:\n",
    "Very fast and scalable.\n",
    "Handles categorical features natively.\n",
    "Often more efficient than XGBoost on large datasets.\n",
    "Disadvantages:\n",
    "Requires careful tuning.\n",
    "Like other boosting methods, it is less interpretable than simpler models like Decision Trees.\n",
    "When to use: When you have large datasets and need high-performance, scalable models.\n",
    "\n",
    "9. Neural Networks (Deep Learning)\n",
    "Description: Neural Networks (or Deep Learning models) consist of multiple layers of interconnected neurons that can learn complex relationships in the data. They are highly flexible and can be applied to a variety of data types, including images, text, and time series.\n",
    "Advantages:\n",
    "Can model highly complex non-linear relationships.\n",
    "Works well with large datasets, especially for unstructured data (images, text).\n",
    "Highly flexible, can be adapted for many different types of problems.\n",
    "Disadvantages:\n",
    "Requires large amounts of data and computational power.\n",
    "Difficult to interpret.\n",
    "Prone to overfitting if not properly regularized.\n",
    "When to use: When you have large datasets and need to capture highly complex relationships, especially in unstructured data like images or text.\n",
    "\n",
    "10. Linear Discriminant Analysis (LDA)\n",
    "Description: LDA is a classification technique that finds the linear combination of features that best separates multiple classes. It assumes that the features for each class are normally distributed and share the same covariance matrix.\n",
    "Advantages:\n",
    "Works well when classes are linearly separable.\n",
    "Computationally less expensive compared to non-linear methods like SVM.\n",
    "Disadvantages:\n",
    "Assumes normality and equal covariance across classes, which may not hold in many cases.\n",
    "Less effective when the data is non-linearly separable.\n",
    "When to use: When the data is approximately linearly separable, and you want a fast, interpretable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1923a-8076-4f83-9c50-409b761bff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question11. What are Classification Evaluation Metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57210210-82df-4c87-9799-2dc71394bd21",
   "metadata": {},
   "source": [
    "Answer\n",
    "Classification Evaluation Metrics are essential tools used to assess the performance of classification models. These metrics help determine how well a model is performing in terms of predicting the correct class labels. Below is a comprehensive overview of the key evaluation metrics commonly used in classification tasks:\n",
    "1.Accuracy is the proportion of correct predictions (both true positives and true negatives) out of all predictions.\n",
    "2.Precision is the proportion of true positive predictions (correctly predicted positives) out of all positive predictions made by the model.\n",
    "3.Recall is the proportion of true positive predictions out of all the actual positives in the data (including both correct and incorrect predictions).\n",
    "4.The F1-score is the harmonic mean of precision and recall, which balances the trade-off between the two metrics. It is particularly useful when the data is imbalanced and neither precision nor recall alone is a good indicator of performance.\n",
    "5.Specificity is the proportion of true negative predictions out of all the actual negatives.\n",
    "6.The MCC is a metric that measures the quality of binary classification, considering all four elements of the confusion matrix (TP, TN, FP, FN). It is a balanced metric that works well even for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11c729-df7e-412b-8359-ccc96f47c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question12. How does class imbalance affect Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7262b163-40f5-4cfa-a51a-05a6a5f60f44",
   "metadata": {},
   "source": [
    "Answer\n",
    "Class imbalance can significantly affect the performance of Logistic Regression, leading to poor performance on the minority class. The model may become biased toward the majority class, resulting in high accuracy but low recall and precision for the minority class. To address this, several techniques can be used:\n",
    "\n",
    "1.Resampling (over-sampling the minority class or under-sampling the majority class).\n",
    "2.Class weighting to make the model more sensitive to the minority class.\n",
    "3.Using appropriate evaluation metrics (precision, recall, F1-score, AUC-ROC) to assessperformance more accurately.\n",
    "4.Adjusting the decision threshold to better balance the prediction of both classes.\n",
    "5.Using ensemble methods like Random Forests or Gradient Boosting for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4d3ce-faf3-41e7-ab49-c3a969cb18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question13. What is Hyperparameter Tuning in Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be70e6-464c-4c59-81e0-44e6d6483a2c",
   "metadata": {},
   "source": [
    "Answer\n",
    "Hyperparameter tuning in Logistic Regression refers to the process of optimizing the parameters that are set before training the model. These hyperparameters affect the performance of the logistic regression model and are not learned from the data during training. Instead, they are manually set by the user or determined through tuning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03398005-57e1-43b9-8e75-e56192aaa599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question14.What are different solvers in Logistic Regression? Which one should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658f85d-84e5-43c2-9e67-4eaf4fa08c2a",
   "metadata": {},
   "source": [
    "Answer\n",
    "Use liblinear if the dataset is small and you need L1 regularization.\n",
    "Use lbfgs for large datasets with L2 regularization.\n",
    "Use saga for large datasets when you need flexibility with L1 or L2 regularization, or if you're working with elastic net regularization.\n",
    "Use sgd when you are working with very large datasets and can afford to fine-tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7cdef-0715-4b46-8a6f-9391766ef4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question15.C How is Logistic Regression extended for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79201645-e53d-4830-805c-c6131624c75e",
   "metadata": {},
   "source": [
    "Answer\n",
    "In Logistic Regression, the algorithm is initially designed for binary classification (predicting two possible outcomes). However, for multiclass classification (when there are more than two classes), Logistic Regression can be extended using two main approaches: One-vs-Rest (OvR) and Multinomial Logistic Regression (Softmax Regression).\n",
    " 1.One-vs-Rest approach, logistic regression is trained separately for each class, treating it as the \"positive\" class, while all other classes are treated as \"negative.\"\n",
    " \n",
    "2. Multinomial Logistic Regression, also known as Softmax Regression, the model is directly extended to handle multiple classes in a single model. Instead of having multiple binary classifiers, multinomial logistic regression uses the softmax function to compute the probabilities for each class based on the input features.\n",
    "\n",
    "The model computes a probability distribution over all the classes by calculating a score (logits) for each class. The softmax function then normalizes these scores to produce a probability value for each class, ensuring the sum of all class probabilities is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0cfdc-c96e-4fc5-bf72-9564c4a0776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question16. What are the advantages and disadvantages of Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22150d-3c4d-4ae0-a5fb-25c7e9cc5f51",
   "metadata": {},
   "source": [
    "Answer\n",
    "Advantages of Logistic Regression:\n",
    "\n",
    "Simplicity and Interpretability:\n",
    "Simple to understand and implement: Logistic Regression is easy to understand conceptually and straightforward to implement in code.\n",
    "Interpretability: It provides clear and interpretable coefficients, which can tell you how each feature influences the outcome. This is particularly useful in applications where model transparency is required, such as in healthcare, finance, and other regulated industries.\n",
    "\n",
    "Efficient for Binary Classification:\n",
    "Logistic Regression works very well for binary classification problems (i.e., predicting two classes). Its probabilistic nature provides an advantage in cases where you need predicted probabilities (for example, for risk assessment).\n",
    "\n",
    "Probabilistic Output:\n",
    "The output of Logistic Regression is a probability, which gives an understanding of the model's certainty about the prediction. This is useful for decision-making (e.g., thresholding the probability for different risk levels).\n",
    "The probabilities produced can be useful for tasks that need confidence levels for classification, rather than just hard class predictions.\n",
    "\n",
    "Scalability:\n",
    "Computationally efficient: Logistic Regression works well for large datasets and is relatively fast to train compared to more complex models like neural networks.\n",
    "It doesnâ€™t require a lot of memory or computational power, making it scalable for both small and large datasets.\n",
    "\n",
    "Works well with Linearly Separable Data:\n",
    "Logistic Regression performs very well when the data is linearly separable, meaning the classes can be separated by a straight line or hyperplane in higher dimensions.\n",
    "\n",
    "Regularization:\n",
    "Logistic Regression supports regularization techniques (such as L1 and L2) that can help in reducing overfitting, especially in high-dimensional feature spaces.\n",
    "\n",
    "Less Prone to Overfitting (with Regularization):\n",
    "Regularized Logistic Regression (using L1 or L2 regularization) can prevent overfitting, making it effective even in cases with high-dimensional data or when the number of features exceeds the number of samples.\n",
    "\n",
    "Disadvantages of Logistic Regression:\n",
    "Assumption of Linearity:\n",
    "Linear decision boundary: Logistic Regression assumes a linear relationship between the input features and the output class. This means it may not perform well on complex, non-linear decision boundaries. For more complex datasets, other algorithms like Decision Trees, SVM, or Neural Networks may perform better.\n",
    "\n",
    "Limited to Binary or Multiclass with Extensions:\n",
    "While Logistic Regression can handle multiclass classification (using techniques like One-vs-Rest or Multinomial Logistic Regression), it is originally designed for binary classification. It requires extensions to handle multiclass classification efficiently, making the setup and tuning more involved.\n",
    "\n",
    "Sensitivity to Feature Scaling:\n",
    "Logistic Regression is sensitive to the scale of the input features. Features with large differences in scale (e.g., one feature in the range 0â€“1 and another in the range 1000â€“10000) can negatively affect the modelâ€™s performance. Feature scaling (such as normalization or standardization) is often required before applying logistic regression.\n",
    "\n",
    "Assumes Independence of Features:\n",
    "Logistic Regression assumes that the features are independent of each other. In cases where features are highly correlated (multicollinearity), the model may produce biased estimates of the coefficients, leading to less reliable predictions. Techniques like Principal Component Analysis (PCA) or Regularization can mitigate this issue.\n",
    "\n",
    "Not Well-Suited for High-Complexity Data:\n",
    "Logistic Regression may struggle when the dataset has high dimensionality (many features) or if there are complex interactions between features that cannot be captured by linear decision boundaries. In such cases, more flexible algorithms like Random Forests, SVM, or Neural Networks might perform better.\n",
    "\n",
    "Overfitting on Small Datasets:\n",
    "While regularization helps prevent overfitting, Logistic Regression can still overfit when trained on small datasets, especially if there are many features. Overfitting can lead to poor generalization performance on unseen data.\n",
    "\n",
    "Requires Large Datasets for Robust Performance:\n",
    "Logistic Regression can require a large amount of data to train effectively, especially when the problem involves many features. For small datasets, it may not perform well and could exhibit high variance.\n",
    "\n",
    "No Support for Non-Linear Relationships (without Transformations):\n",
    "By default, Logistic Regression is linear in nature, meaning that it wonâ€™t capture non-linear relationships between features and the target variable. Although you can use feature transformations (such as polynomial features) to introduce non-linearities, the model itself doesnâ€™t inherently model complex relationships.\n",
    "\n",
    "Assumes No Outliers:\n",
    "Logistic Regression is sensitive to outliers. Outliers in the dataset can affect the modelâ€™s coefficients and predictions, leading to reduced performance. Preprocessing steps to handle outliers are important when using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3ca36-ae30-424e-a20c-084ea27167aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question17. What are some use cases of Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9060b2-d096-425a-9d4f-2d5e6fa5f85c",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Logistic Regression is widely used in domains where the goal is to predict a binary or probabilistic outcome. Some of its most common applications include:\n",
    "\n",
    "Healthcare (diagnosis, risk prediction)\n",
    "Marketing (customer churn, CTR)\n",
    "Finance (credit scoring, fraud detection)\n",
    "Social Sciences (survey analysis, voting behavior)\n",
    "Retail & E-commerce (purchase prediction)\n",
    "NLP & Text Analysis (sentiment analysis)\n",
    "Manufacturing & Quality Control (defect detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c0b75-ab12-44b8-a677-0b43b10f38a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question18. What is the difference between Softmax Regression and Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb327bb-d170-4384-b4c3-b740208d8a37",
   "metadata": {},
   "source": [
    "Answer\n",
    "1.Nature of Classification Problem:\n",
    "Logistic Regression:\n",
    "Primarily used for binary classification (i.e., problems where the target variable has two classes).\n",
    "The output is the probability of belonging to one of the two classes (e.g., 0 or 1), and the model uses the sigmoid function to map predictions to a probability between 0 and 1.\n",
    "Softmax Regression (Multinomial Logistic Regression):\n",
    "Used for multiclass classification (i.e., problems where the target variable has more than two classes).\n",
    "\n",
    "2.Activation Function Used:\n",
    "Logistic Regression:\n",
    "Uses the sigmoid function for binary classification. The sigmoid function squashes the output to a value between 0 and 1\n",
    "It outputs a probability for just one class (usually class 1), and the complement (1 - probability) gives the probability for class 0.\n",
    "Softmax Regression:\n",
    "Uses the softmax function for multiclass classification. The softmax function calculates the probabilities of each class in the output vector by comparing the relative scores (logits) for each class\n",
    "This ensures that the output is a probability distribution across all classes, with the sum of probabilities equal to 1.\n",
    "\n",
    "3.Model Output:\n",
    "Logistic Regression:\n",
    "Outputs a single probability value between 0 and 1, which is interpreted as the probability of class 1 (the positive class) in a binary classification task.\n",
    "The class with the highest probability is chosen as the predicted class (usually 0 or 1).\n",
    "Softmax Regression:\n",
    "Outputs a probability distribution across multiple classes (e.g., for three classes, it gives three probabilities that sum to 1).\n",
    "The class with the highest probability is selected as the predicted class (i.e., the class with the highest softmax score).\n",
    "\n",
    "4.Usage in Multiclass Classification:\n",
    "Logistic Regression:\n",
    "Not directly suited for multiclass classification. However, it can be adapted for multiclass problems using techniques like One-vs-Rest (OvR), where multiple binary classifiers are trained, each one responsible for predicting whether an instance belongs to a particular class or not.\n",
    "Softmax Regression:\n",
    "Naturally suited for multiclass classification. It directly handles multiclass problems by modeling the probabilities of each class simultaneously in a single model.\n",
    "\n",
    "5.Complexity and Computational Cost:\n",
    "Logistic Regression:\n",
    "Logistic regression is relatively simpler and computationally cheaper because it only deals with binary classification and uses a sigmoid function, which is computationally less expensive than the softmax function.\n",
    "Softmax Regression:\n",
    "Softmax regression involves computing the softmax function for multiple classes and is generally more computationally expensive than logistic regression, especially when the number of classes is large.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e2026-fb14-44e4-aff6-0dfff5cd5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73847df6-2512-4b7f-94ea-341c39986a4b",
   "metadata": {},
   "source": [
    "Answer\n",
    "Softmax Regression is the more efficient, natural, and robust choice for multiclass classification when classes are mutually exclusive and you want a single model that can output a probability distribution across all classes.\n",
    "One-vs-Rest (OvR) is a flexible approach, especially when you need to use different classifiers for each class, or when you're working with multi-label problems or non-mutually exclusive classes. However, it can be computationally more expensive and prone to errors due to the independent nature of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848b880-1d64-44eb-9688-a0eb421c4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question20. How do we interpret coefficients in Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae65507-1d5c-4878-99a2-52c0d5d4f8f9",
   "metadata": {},
   "source": [
    "Answer\n",
    " Interpretation:\n",
    "Coefficient (Î²i): Represents the change in log-odds of the positive class for a one-unit increase in the feature, with all other features held constant.\n",
    "Odds Ratio (eÎ²i): Represents the multiplicative change in the odds of the positive class for a one-unit increase in the feature, with all other features held constant.\n",
    "OR > 1: Feature increases the odds of the positive class.\n",
    "OR < 1: Feature decreases the odds of the positive class.\n",
    "OR = 1: Feature has no effect on the odds.\n",
    "Interpretability: Logistic regressionâ€™s coefficients are interpretable in terms of log-odds or odds ratios, making it easy to understand the effect of each feature on the probability of the target class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7196c0-42b1-41e1-ba68-f86e250dcda9",
   "metadata": {},
   "source": [
    "#PRACTICAL\n",
    "#Question1.Write a Python program that loads a dataset, splits it into training and testing sets, applies LogisticRegression, and prints the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d3a49-4627-4a03-b3d0-b40c2ae83d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.datasets import load_iris\r\n",
    "from sklearn.metrics import accuracy_scotaset\r\n",
    "data = load_iris()\r\n",
    "X = datFeatures\r\n",
    "y = data #0% testing)\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, randomgression model\r\n",
    "model = LogisticRegression(the training data\r\n",
    "model.fit(Xdict on the test set\r\n",
    "y_pred = morint the model accuracy\r\n",
    "accuracy = accuracy_score(y_test, y_pred)\r\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c83ccb-9f25-460e-add2-39197015d9e5",
   "metadata": {},
   "source": [
    "#Question2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198bd5a5-09ff-445c-b974-93f219bcfdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy with L1 regularization: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#Answer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy with L1 regularization: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1111b2b-2105-4ed8-a127-3ddd7a0fde6f",
   "metadata": {},
   "source": [
    "Question3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\r\n",
    "LogisticRegression(penalty='l2'). Print model accuracy and coefficient?\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7e664a-a53c-403e-96cc-8e98fcd7782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy with L2 regularization (Ridge): 100.00%\n",
      "Model coefficients:\n",
      "[[ 0.3711229   1.409712   -2.15210117 -0.95474179]\n",
      " [ 0.49400451 -1.58897112  0.43717015 -1.11187838]\n",
      " [-1.55895271 -1.58893375  2.39874554  2.15556209]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=200)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy with L2 regularization (Ridge): {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"Model coefficients:\")\n",
    "print(model.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877ed53-35b5-4300-96e3-bf21660e1b41",
   "metadata": {},
   "source": [
    "Question4.C Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d0377b-5a09-4ed4-8d16-1363d9624828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy with Elastic Net regularization: 100.00%\n",
      "Model coefficients:\n",
      "[[ 0.3867373   1.77346208 -2.42378977 -0.70315584]\n",
      " [ 0.07790522  0.          0.         -0.58427358]\n",
      " [-1.25687841 -1.52930709  2.59567853  2.07734749]]\n"
     ]
    }
   ],
   "source": [
    "#Answer\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=200, l1_ratio=0.5)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy with Elastic Net regularization: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"Model coefficients:\")\n",
    "print(model.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d34701-002d-4f35-8f7c-a3e7013456cd",
   "metadata": {},
   "source": [
    "Question5.C Write a Python program to train a Logistic Regression model for multiclass classification using \n",
    "multi_class='ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f8c922-ac48-495b-862a-9557eab3b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy with OvR multiclass classification: 100.00%\n",
      "Model coefficients:\n",
      "[[ 0.3711229   1.409712   -2.15210117 -0.95474179]\n",
      " [ 0.49400451 -1.58897112  0.43717015 -1.11187838]\n",
      " [-1.55895271 -1.58893375  2.39874554  2.15556209]]\n",
      "Model intercepts:\n",
      "[ 0.2478905   0.86408083 -1.00411267]\n"
     ]
    }
   ],
   "source": [
    "#Answer\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy with OvR multiclass classification: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"Model coefficients:\")\n",
    "print(model.coef_)\n",
    "\n",
    "\n",
    "print(\"Model intercepts:\")\n",
    "print(model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6415bb06-571d-4aa2-847d-ac648cff1db4",
   "metadata": {},
   "source": [
    "Question6.Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic \n",
    "Regression. Print the best parameters and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42dd4ed7-a5a1-4227-afd1-3a3ed66b8f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2'}\n",
      "Best Cross-Validation Accuracy: 96.67%\n",
      "Test Set Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.85833333        nan 0.93333333        nan 0.96666667\n",
      "        nan 0.94166667        nan 0.95      ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Answer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data  \n",
    "y = data.target \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  \n",
    "    'penalty': ['l1', 'l2']         \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc2df0-e013-4002-8a63-f18396a31d20",
   "metadata": {},
   "source": [
    "Question7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94c9dac5-ed94-48e4-baac-3bbfa162092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for each fold: [1.         0.96666667 0.93333333 1.         0.93333333]\n",
      "Average accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "#Answer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "accuracies = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy for each fold: {accuracies}\")\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Average accuracy: {average_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d42e41-9b4a-4999-908b-b877c48dc068",
   "metadata": {},
   "source": [
    "Question8.Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84dde1f5-a0e6-4906-9454-0e9dc539fcbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     12\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "X = df.iloc[:, :-1]  \n",
    "y = df.iloc[:, -1]   \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bccbad-2d27-49f3-9ae4-3c512fa01e5f",
   "metadata": {},
   "source": [
    "Question9.M Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in \n",
    "Logistic Regression. Print the best parameters and accurac?M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a98f0af-b6ab-40dd-9577-e97f9376ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.4452048365748854, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best Cross-Validation Accuracy: 97.50%\n",
      "Test Set Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import uniform, loguniform\n",
    "\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "\n",
    "param_dist = {\n",
    "    'C': loguniform(1e-4, 1e4),  \n",
    "    'penalty': ['l1', 'l2'],      \n",
    "    'solver': ['liblinear', 'saga']  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=logreg, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, random_state=42, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_accuracy = random_search.best_score_\n",
    "\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc31fa9-8427-4891-84cb-52855155139b",
   "metadata": {},
   "source": [
    "Question10.Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67fdde11-0286-4fcf-83f3-99efe7e20a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of OvO Logistic Regression: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#Answer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "\n",
    "\n",
    "ovo_classifier = OneVsOneClassifier(logreg)\n",
    "\n",
    "\n",
    "ovo_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = ovo_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of OvO Logistic Regression: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804cf6f4-4af3-4921-bd13-22c8b361177e",
   "metadata": {},
   "source": [
    "Question11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary cclassificatio?Mn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a76b0acb-6eb9-48e2-80d8-c99f7f138f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 95.61%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Answer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "            xticklabels=[\"Malignant\", \"Benign\"], yticklabels=[\"Malignant\", \"Benign\"])\n",
    "plt.title(\"Confusion Matrix for Binary Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d3f271-5a05-42b4-98b0-d454507e7639",
   "metadata": {},
   "source": [
    "Question12.M Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
    "Recall, and F1-ScoreM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bef5f352-e3a5-40db-947b-e31e5c936202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.97      0.91      0.94        43\n",
      "      Benign       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=['Malignant', 'Benign'])\n",
    "\n",
    "\n",
    "print(\"Performance Evaluation:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d102d-eacb-4414-977d-244396baa7c4",
   "metadata": {},
   "source": [
    "Question13.Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to \n",
    "improve model performancM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cd62ace-082d-443a-b1ed-9977c753e53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation with Class Weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.98      0.95      0.96        43\n",
      "      Benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy: 97.37%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Model Evaluation with Class Weights:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Malignant', 'Benign']))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24a01c-ef10-4bf4-8d17-42e8f9783b91",
   "metadata": {},
   "source": [
    "Question14.M Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and \n",
    "evaluate performancM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fdf6461-1350-40fd-afac-36ecfb9fe64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   Survived  Pclass                                               Name  \\\n",
      "0         0       3                             Mr. Owen Harris Braund   \n",
      "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
      "2         1       3                              Miss. Laina Heikkinen   \n",
      "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
      "4         0       3                            Mr. William Henry Allen   \n",
      "\n",
      "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
      "0    male  22.0                        1                        0   7.2500  \n",
      "1  female  38.0                        1                        0  71.2833  \n",
      "2  female  26.0                        0                        0   7.9250  \n",
      "3  female  35.0                        1                        0  53.1000  \n",
      "4    male  35.0                        0                        0   8.0500  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Ticket', 'Cabin'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]])  \n\u001b[1;32m---> 21\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicket\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     24\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m     25\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Ticket', 'Cabin'] not found in axis\""
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "url = \"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df['Age'] = imputer.fit_transform(df[['Age']])  \n",
    "\n",
    "\n",
    "df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Sex'] = le.fit_transform(df['Sex'])\n",
    "df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})  \n",
    "\n",
    "\n",
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]  \n",
    "y = df['Survived']  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Did Not Survive', 'Survived']))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb239304-d04f-46b0-970c-299a705cc592",
   "metadata": {},
   "source": [
    "Question15.Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcad9dfb-d011-471c-ab4a-35dd7f3f132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 95.61%\n",
      "Accuracy with scaling: 97.37%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_no_scaling = logreg.predict(X_test)\n",
    "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
    "print(f\"Accuracy without scaling: {accuracy_no_scaling * 100:.2f}%\")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_with_scaling = logreg.predict(X_test_scaled)\n",
    "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
    "print(f\"Accuracy with scaling: {accuracy_with_scaling * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a8484-955a-4844-84aa-de3fc0530485",
   "metadata": {},
   "source": [
    "Question16.Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c32385c3-0bd5-48a5-b019-5ed0bfa0498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score: 0.9977\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"ROC-AUC score: {roc_auc:.4f}\")\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--') \n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e638b6b8-d478-40be-817b-afcb027fe93b",
   "metadata": {},
   "source": [
    "Question17.Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate \n",
    "accurac?M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03772247-44dd-4daa-a982-5abc9178257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with C=0.5: 96.49%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data  \n",
    "y = data.target \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(C=0.5, max_iter=10000)\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with C=0.5: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f977fc6-96b7-4dc7-a568-b4dc8232eaed",
   "metadata": {},
   "source": [
    "Question18.Write a Python program to train Logistic Regression and identify important features based on model \n",
    "coefficientM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00b4eebe-680a-4e50-baae-942818310498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important Features based on Coefficients:\n",
      "                    Feature  Coefficient\n",
      "26          worst concavity    -1.411667\n",
      "11            texture error     1.387102\n",
      "0               mean radius     0.983540\n",
      "25        worst compactness    -0.764503\n",
      "28           worst symmetry    -0.731406\n",
      "6            mean concavity    -0.520178\n",
      "21            worst texture    -0.514710\n",
      "27     worst concave points    -0.496308\n",
      "2            mean perimeter    -0.368323\n",
      "24         worst smoothness    -0.302212\n",
      "7       mean concave points    -0.274086\n",
      "5          mean compactness    -0.231719\n",
      "1              mean texture     0.226157\n",
      "8             mean symmetry    -0.222870\n",
      "12          perimeter error    -0.162913\n",
      "4           mean smoothness    -0.153082\n",
      "29  worst fractal dimension    -0.101054\n",
      "20             worst radius     0.100387\n",
      "10             radius error    -0.093944\n",
      "13               area error    -0.089151\n",
      "16          concavity error    -0.046024\n",
      "15        compactness error     0.043980\n",
      "9    mean fractal dimension    -0.036773\n",
      "18           symmetry error    -0.034070\n",
      "17     concave points error    -0.031495\n",
      "3                 mean area     0.026306\n",
      "14         smoothness error    -0.021893\n",
      "22          worst perimeter    -0.017068\n",
      "23               worst area    -0.016594\n",
      "19  fractal dimension error     0.011057\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "coefficients = logreg.coef_[0]\n",
    "\n",
    "\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "\n",
    "coeff_df['Absolute Coefficient'] = np.abs(coeff_df['Coefficient'])\n",
    "coeff_df_sorted = coeff_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "\n",
    "print(\"Important Features based on Coefficients:\")\n",
    "print(coeff_df_sorted[['Feature', 'Coefficient']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8c95f-a8a8-43bc-8045-d9fe46b1d2f4",
   "metadata": {},
   "source": [
    "Question19. Write a Python program to train Logistic Regression and evaluate its performance using Cohenâ€™s Kappa \n",
    "Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "026f7635-14c4-42e4-844b-846107b0d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.61%\n",
      "Cohen's Kappa Score: 0.9053\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Cohen's Kappa Score: {kappa:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aecdb23-c463-4757-8c69-123a6a4547c7",
   "metadata": {},
   "source": [
    "Question20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary \n",
    "classificatin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc3eba54-649f-4051-b5f4-223ecb0791b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAIhCAYAAACsQmneAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABV2klEQVR4nO39f1xUdf7//98HGH6pYGoCKiKapWQq4i80NU0wNX9smVQuqauVsZsp1esja2pmremWoqX2S6VaSzZN+2UJbmWaZv4Ac9Uyf0UqZJiGhsIA5/uHX+bdNKiAwDBnb9fLhctr5znPc56PMw94dffMmTMWwzAMAQAAACbl4eoCAAAAgOpE4AUAAICpEXgBAABgagReAAAAmBqBFwAAAKZG4AUAAICpEXgBAABgagReAAAAmBqBFwAAAKZG4AXgUikpKbJYLPYfLy8vNWvWTGPHjtXx48drvJ4xY8aoRYsWFdrm6NGjslgsSklJqZaarmTMmDEOr6G3t7datWqlxx57THl5eS6p6ffKen1K+3706NFy7eObb77R2LFjFR4eLl9fX9WtW1edOnXS3Llz9csvv1RP4QBMw8vVBQCAJC1fvlxt2rTR+fPn9cUXX2j27NnauHGj9uzZozp16tRYHdOmTdMjjzxSoW1CQkK0detWtWrVqpqqujI/Pz99+umnkqQzZ85o1apVev755/XNN98oLS3NZXVVhVdffVUJCQm64YYb9PjjjysiIkI2m007duzQSy+9pK1bt2rNmjWuLhNALUbgBVArtGvXTp07d5Yk9e3bV8XFxZo1a5bWrl2rUaNGlblNfn6+/P39q7SOyoRWHx8fde/evUrrqCgPDw+HGm677TYdPnxY6enpOnLkiMLDw11YXeVt3bpVDz30kGJiYrR27Vr5+PjYn4uJidGjjz6qTz75pErWOn/+vHx9fWWxWKpkfwBqDy5pAFArlYa3H374QdLFt+3r1q2rPXv2KDY2VvXq1dOtt94qSSosLNTTTz+tNm3ayMfHR9dee63Gjh2rn3/+2Wm/b731lqKjo1W3bl3VrVtXHTt21NKlS+3Pl3VJwzvvvKNu3bopMDBQ/v7+atmypf7yl7/Yn7/UJQ2bN2/Wrbfeqnr16snf3189evTQRx995DCn9K39zz77TA899JAaNWqkhg0b6o477tCJEycq/fpJsv8D4qeffnIYT01NVXR0tOrUqaO6detqwIABysjIcNp+27ZtGjJkiBo2bChfX1+1atVKkyZNsj9/8OBBjR07Vq1bt5a/v7+aNm2qIUOGaM+ePVdV9+/94x//kMVi0SuvvOIQdkt5e3tr6NCh9scWi0VPPvmk07wWLVpozJgx9selr3taWpr+8pe/6Nprr5W/v79SU1NlsVj0n//8x2kfS5YskcVi0TfffGMf27Fjh4YOHaoGDRrI19dXkZGR+ve//311Bw2gyhF4AdRKBw8elCRde+219rHCwkINHTpU/fr103vvvaeZM2eqpKREw4YN07PPPqt7771XH330kZ599lmlp6frlltu0fnz5+3bT58+XaNGjVKTJk2UkpKiNWvWaPTo0fZQXZatW7cqLi5OLVu21MqVK/XRRx9p+vTpKioqumz9GzduVL9+/fTrr79q6dKlevvtt1WvXj0NGTJEqampTvPHjx8vq9Wqt956S3PnztXnn3+uP//5zxV92RwcOXJEXl5eatmypX3sH//4h+655x5FRETo3//+t958802dPXtWvXr10r59++zz1q9fr169eikrK0vz5s3Txx9/rCeeeMIhPJ84cUINGzbUs88+q08++USLFi2Sl5eXunXrpu++++6qapek4uJiffrpp4qKilJoaOhV768sf/nLX2S1WvXmm29q1apV+tOf/qTGjRtr+fLlTnNTUlLUqVMntW/fXpL02WefqWfPnjpz5oxeeuklvffee+rYsaPi4uJcdj03gEswAMCFli9fbkgyvvrqK8Nmsxlnz541PvzwQ+Paa6816tWrZ+Tk5BiGYRijR482JBnLli1z2P7tt982JBmrV692GN++fbshyVi8eLFhGIZx+PBhw9PT0xg1atRl6xk9erQRFhZmf/zcc88ZkowzZ85ccpsjR44Ykozly5fbx7p37240btzYOHv2rH2sqKjIaNeundGsWTOjpKTE4fgTEhIc9jl37lxDkpGdnX3ZektrrlOnjmGz2QybzWbk5uYaS5YsMTw8PIy///3v9nlZWVmGl5eX8fDDDztsf/bsWSM4ONgYOXKkfaxVq1ZGq1atjPPnz19x/d8fX2FhodG6dWtj8uTJ9vGyXp/S4z5y5Mgl95eTk2NIMu6+++5y1yDJmDFjhtN4WFiYMXr0aKf177vvPqe5iYmJhp+fn0PP9+3bZ0gyXnjhBftYmzZtjMjISMNmszlsf/vttxshISFGcXFxuesGUL04wwugVujevbusVqvq1aun22+/XcHBwfr4448VFBTkMO/OO+90ePzhhx+qfv36GjJkiIqKiuw/HTt2VHBwsD7//HNJUnp6uoqLi/XXv/61QnV16dJFkjRy5Ej9+9//LtedI3777Tdt27ZNI0aMUN26de3jnp6eio+P17Fjx5zOgP7+bXlJ9rOIpWefS0pKHI6vuLjYaU2r1Sqr1apGjRrpoYceUlxcnJ555hn7nPXr16uoqEj33Xefw758fX3Vp08f+2t14MABHTp0SOPGjZOvr+8lj7OoqEj/+Mc/FBERIW9vb3l5ecnb21vff/+99u/ff8XXqTb44++TdPGs7/nz5x3OxC9fvlw+Pj669957JV18B+Lbb7+1X1/++9dz0KBBys7OrpKz3ACqBoEXQK3wxhtvaPv27crIyNCJEyf0zTffqGfPng5z/P39FRAQ4DD2008/6cyZM/L29rYHvtKfnJwc5ebmSpL9et5mzZpVqK7evXtr7dq19qDYrFkztWvXTm+//fYltzl9+rQMw1BISIjTc02aNJEknTp1ymG8YcOGDo9Lr1ctvSTjqaeecji2P364zs/PT9u3b9f27dv1wQcf6JZbbtHbb7+tZ5991j6n9HKELl26OL1WqampFX6tEhMTNW3aNA0fPlwffPCBtm3bpu3bt6tDhw4Ol5JUVqNGjeTv768jR45c9b4upawe3XjjjerSpYv9sobi4mL961//0rBhw9SgQQNJ/++1fOyxx5xey4SEBEmyv54AXI+7NACoFdq2bWv/kNWllPXp+dIPeV3qk/r16tWT9P+uBT527FiFrwcdNmyYhg0bpoKCAn311VeaPXu27r33XrVo0ULR0dFO86+55hp5eHgoOzvb6bnSD6I1atSoQjU88MADuv322+2P//gBLg8PD4fXLyYmRlFRUZo5c6ZGjRql0NBQ+5qrVq1SWFjYJdf6/Wt1Of/6179033336R//+IfDeG5ururXr1+u47ocT09P3Xrrrfr444917Nixcv1jxcfHRwUFBU7jf/wHRqlL3ZFh7NixSkhI0P79+3X48GFlZ2dr7Nix9udLX8ukpCTdcccdZe7jhhtuuGK9AGoGgReAW7v99tu1cuVKFRcXq1u3bpecFxsbK09PTy1ZsqTMkFoePj4+6tOnj+rXr6/169crIyOjzH3VqVNH3bp107vvvqvnnntOfn5+ki5elvCvf/1LzZo10/XXX1+htZs0aWI/O1zeWhctWqRbbrlFTz/9tF5++WUNGDBAXl5eOnToUJlv5Ze6/vrr1apVKy1btkyJiYll3h1BuhgW//jcRx99pOPHj+u6664rd62Xk5SUpHXr1un+++/Xe++9J29vb4fnbTabPvnkEw0ZMkTSxbsx/P4uCpL06aef6ty5cxVa95577lFiYqJSUlJ0+PBhNW3aVLGxsfbnb7jhBrVu3Vq7d+92CvwAah8CLwC3dvfdd2vFihUaNGiQHnnkEXXt2lVWq1XHjh3TZ599pmHDhulPf/qTWrRoob///e+aNWuWzp8/r3vuuUeBgYHat2+fcnNzNXPmzDL3P336dB07dky33nqrmjVrpjNnzmjBggWyWq3q06fPJeuaPXu2YmJi1LdvXz322GPy9vbW4sWL9d///ldvv/12jdzrtU+fPho0aJCWL1+uKVOmKDw8XE899ZSmTp2qw4cP67bbbtM111yjn376SV9//bXq1Kljfx0WLVqkIUOGqHv37po8ebKaN2+urKwsrV+/XitWrJB08R8bKSkpatOmjdq3b6+dO3fqn//8Z4UvG7mc6OhoLVmyRAkJCYqKitJDDz2kG2+8UTabTRkZGXrllVfUrl07e+CNj4/XtGnTNH36dPXp00f79u3Tiy++qMDAwAqtW79+ff3pT39SSkqKzpw5o8cee0weHo5XAb788ssaOHCgBgwYoDFjxqhp06b65ZdftH//fu3atUvvvPNOlb0OAK6Sqz81B+B/W+mn5bdv337ZeaV3IiiLzWYznnvuOaNDhw6Gr6+vUbduXaNNmzbGgw8+aHz//fcOc9944w2jS5cu9nmRkZEOdw/4410aPvzwQ2PgwIFG06ZNDW9vb6Nx48bGoEGDjE2bNtnnlHUXAsMwjE2bNhn9+vUz6tSpY/j5+Rndu3c3Pvjgg3Id/2effWZIMj777LPLvi5Xem327NljeHh4GGPHjrWPrV271ujbt68REBBg+Pj4GGFhYcaIESOMDRs2OGy7detWY+DAgUZgYKDh4+NjtGrVyuHuC6dPnzbGjRtnNG7c2PD39zduvvlmY9OmTUafPn2MPn36XPb1Kc9dGn4vMzPTGD16tNG8eXPD29vbqFOnjhEZGWlMnz7dOHnypH1eQUGB8X//939GaGio4efnZ/Tp08fIzMy85F0aLvd7l5aWZkgyJBkHDhwoc87u3buNkSNHGo0bNzasVqsRHBxs9OvXz3jppZfKdVwAaobFMAzDZWkbAAAAqGbcpQEAAACmRuAFAACAqRF4AQAAYGoEXgAAAJgagRcAAACmRuAFAACAqfHFE2UoKSnRiRMnVK9evRq5OTwAAAAqxjAMnT17Vk2aNHH6Ypg/IvCW4cSJEwoNDXV1GQAAALiCH3/88Yrf8EjgLUO9evUkXXwBAwICqn09m82mtLQ0xcbGymq1Vvt6qHr00P3RQ/dHD90b/XN/Nd3DvLw8hYaG2nPb5RB4y1B6GUNAQECNBV5/f38FBATwR+6m6KH7o4fujx66N/rn/lzVw/JcfsqH1gAAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYmksD7xdffKEhQ4aoSZMmslgsWrt27RW32bhxo6KiouTr66uWLVvqpZdecpqzevVqRUREyMfHRxEREVqzZk01VA8AAAB34NLA+9tvv6lDhw568cUXyzX/yJEjGjRokHr16qWMjAz9/e9/18SJE7V69Wr7nK1btyouLk7x8fHavXu34uPjNXLkSG3btq26DgMAAAC1mJcrFx84cKAGDhxY7vkvvfSSmjdvruTkZElS27ZttWPHDj333HO68847JUnJycmKiYlRUlKSJCkpKUkbN25UcnKy3n777So/hqqQmSlt3RqiggKLvFzaEVRWUZFFu3bRQ3dGD90fPXRv9K92aNFC6tTJ1VVUPbf6ldq6datiY2MdxgYMGKClS5fKZrPJarVq69atmjx5stOc0pBcloKCAhUUFNgf5+XlSZJsNptsNlvVHcAlvPaa9MorXat9HVQnL0n00L3RQ/dHD90b/astvvnGpjZtKr5daWaqiexU0XXcKvDm5OQoKCjIYSwoKEhFRUXKzc1VSEjIJefk5ORccr+zZ8/WzJkzncbT0tLk7+9fNcVfRmFhK7VtG1Lt6wAAAFzKoUOBKiz00po1X6tDh9xK7yc9Pb0Kq7q0/Pz8cs91q8ArSRaLxeGxYRhO42XN+ePY7yUlJSkxMdH+OC8vT6GhoYqNjVVAQEBVlH1ZMTE2paenKyYmRlartdrXQ9Wz2eihu6OH7o8eujf653qRkZ7au1fq1q2b+vUzKrx9Tfew9B358nCrwBscHOx0pvbkyZPy8vJSw4YNLzvnj2d9f8/Hx0c+Pj5O41artUb/6Gp6PVQ9euj+6KH7o4fujf65Tum5QS8vL11NC2qqhxVZw63uwxsdHe10mjwtLU2dO3e2H/Sl5vTo0aPG6gQAAEDt4dIzvOfOndPBgwftj48cOaLMzEw1aNBAzZs3V1JSko4fP6433nhDkjRhwgS9+OKLSkxM1P3336+tW7dq6dKlDndfeOSRR9S7d2/NmTNHw4YN03vvvacNGzZo8+bNNX58AAAAcD2XnuHdsWOHIiMjFRkZKUlKTExUZGSkpk+fLknKzs5WVlaWfX54eLjWrVunzz//XB07dtSsWbO0cOFC+y3JJKlHjx5auXKlli9frvbt2yslJUWpqanq1q1bzR4cAAAAagWXnuG95ZZb7B86K0tKSorTWJ8+fbRr167L7nfEiBEaMWLE1ZYHAAAAE3Cra3gBAACAiiLwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNS8XF0AAAAAao+CAunnn6W8POefsDDp5ptdXWHFEXgBAABgN3jw5Z//4QepefOaqaWqcEkDAAAA1KWL4+O6daUmTaQ2baSuXSVv74vjP/9c87VdLQIvAAAAtHSpdPy4dOaMVFQknT178fH+/dK2bVJQkKsrrDwuaQAAAIAslotndM2IM7wAAAAwNQIvAAAATI3ACwAAAFMj8AIAAMDUCLwAAAAwNQIvAAAATI3ACwAAAFMj8AIAAMDUCLwAAAAwNQIvAAAATI3ACwAAAFMj8AIAAMDUCLwAAAAwNQIvAAAATI3ACwAAAFMj8AIAAMDUCLwAAAAwNQIvAAAATM3lgXfx4sUKDw+Xr6+voqKitGnTpsvOX7Rokdq2bSs/Pz/dcMMNeuONNxyeT0lJkcVicfq5cOFCdR4GAAAAaikvVy6empqqSZMmafHixerZs6defvllDRw4UPv27VPz5s2d5i9ZskRJSUl69dVX1aVLF3399de6//77dc0112jIkCH2eQEBAfruu+8ctvX19a324wEAAEDt49LAO2/ePI0bN07jx4+XJCUnJ2v9+vVasmSJZs+e7TT/zTff1IMPPqi4uDhJUsuWLfXVV19pzpw5DoHXYrEoODi43HUUFBSooKDA/jgvL0+SZLPZZLPZKnVsFVG6Rk2shepBD90fPXR/9NC90T934CXJoqIim8pqU033sCLruCzwFhYWaufOnZoyZYrDeGxsrLZs2VLmNgUFBU5nav38/PT111/LZrPJarVKks6dO6ewsDAVFxerY8eOmjVrliIjIy9Zy+zZszVz5kyn8bS0NPn7+1f00CotPT29xtZC9aCH7o8euj966N7oX+11/nyMJH9t3vylcnJ+veS8muphfn5+uee6LPDm5uaquLhYQUFBDuNBQUHKyckpc5sBAwbotdde0/Dhw9WpUyft3LlTy5Ytk81mU25urkJCQtSmTRulpKTopptuUl5enhYsWKCePXtq9+7dat26dZn7TUpKUmJiov1xXl6eQkNDFRsbq4CAgKo76Euw2WxKT09XTEyMPbTDvdBD90cP3R89dG/0r/bz87sYG2++uac6dXJ+vqZ7WPqOfHm49JIG6eLlB79nGIbTWKlp06YpJydH3bt3l2EYCgoK0pgxYzR37lx5enpKkrp3767u3bvbt+nZs6c6deqkF154QQsXLixzvz4+PvLx8XEat1qtNfpHV9ProerRQ/dHD90fPXRv9K/28/Ky6nItqqkeVmQNl92loVGjRvL09HQ6m3vy5Emns76l/Pz8tGzZMuXn5+vo0aPKyspSixYtVK9ePTVq1KjMbTw8PNSlSxd9//33VX4MAAAAqP1cFni9vb0VFRXldJ1Henq6evTocdltrVarmjVrJk9PT61cuVK33367PDzKPhTDMJSZmamQkJAqqx0AAADuw6WXNCQmJio+Pl6dO3dWdHS0XnnlFWVlZWnChAmSLl5be/z4cfu9dg8cOKCvv/5a3bp10+nTpzVv3jz997//1euvv27f58yZM9W9e3e1bt1aeXl5WrhwoTIzM7Vo0SKXHCMAAABcy6WBNy4uTqdOndJTTz2l7OxstWvXTuvWrVNYWJgkKTs7W1lZWfb5xcXFev755/Xdd9/JarWqb9++2rJli1q0aGGfc+bMGT3wwAPKyclRYGCgIiMj9cUXX6hr1641fXgAAACoBVz+obWEhAQlJCSU+VxKSorD47Zt2yojI+Oy+5s/f77mz59fVeUBAADAzbn8q4UBAACA6kTgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAAV62oSDIMV1dRNpd/0xoAAADcx9atUmam9MMP0tGj/+//Hj/upeDgfurfX7JaXVzkHxB4AQAAUG4PP3ypZyw6fryejh2zqU2bmqzoygi8AAAAuKI775SWLpWaNpVatJDCwhz/b//+hvLzLS6usmwEXgAAAFzR/PkXfy7F07PmaqkoPrQGAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1lwfexYsXKzw8XL6+voqKitKmTZsuO3/RokVq27at/Pz8dMMNN+iNN95wmrN69WpFRETIx8dHERERWrNmTXWVDwAAgFrOpYE3NTVVkyZN0tSpU5WRkaFevXpp4MCBysrKKnP+kiVLlJSUpCeffFJ79+7VzJkz9de//lUffPCBfc7WrVsVFxen+Ph47d69W/Hx8Ro5cqS2bdtWU4cFAACAWsSlgXfevHkaN26cxo8fr7Zt2yo5OVmhoaFasmRJmfPffPNNPfjgg4qLi1PLli119913a9y4cZozZ459TnJysmJiYpSUlKQ2bdooKSlJt956q5KTk2voqAAAAFCbeLlq4cLCQu3cuVNTpkxxGI+NjdWWLVvK3KagoEC+vr4OY35+fvr6669ls9lktVq1detWTZ482WHOgAEDLht4CwoKVFBQYH+cl5cnSbLZbLLZbBU5rEopXaMm1kL1oIfujx66P3ro3uifGVyMlUVFRaqJNlbkd8VlgTc3N1fFxcUKCgpyGA8KClJOTk6Z2wwYMECvvfaahg8frk6dOmnnzp1atmyZbDabcnNzFRISopycnArtU5Jmz56tmTNnOo2npaXJ39+/EkdXOenp6TW2FqoHPXR/9ND90UP3Rv/cV1HRIElWbd68WYcO5Vf7evn55V/DZYG3lMVicXhsGIbTWKlp06YpJydH3bt3l2EYCgoK0pgxYzR37lx5enpWap+SlJSUpMTERPvjvLw8hYaGKjY2VgEBAZU5rAqx2WxKT09XTEyMrFZrta+HqkcP3R89dH/00L3RP/fn5XUxVt5888264Ybqj5il78iXh8sCb6NGjeTp6el05vXkyZNOZ2hL+fn5admyZXr55Zf1008/KSQkRK+88orq1aunRo0aSZKCg4MrtE9J8vHxkY+Pj9O41Wqt0T+6ml4PVY8euj966P7ooXujf+7MkHQx+NZEDyuyhss+tObt7a2oqCinty7S09PVo0ePy25rtVrVrFkzeXp6auXKlbr99tvl4XHxUKKjo532mZaWdsV9AgAAwJxceklDYmKi4uPj1blzZ0VHR+uVV15RVlaWJkyYIOnipQbHjx+332v3wIED+vrrr9WtWzedPn1a8+bN03//+1+9/vrr9n0+8sgj6t27t+bMmaNhw4bpvffe04YNG7R582aXHCMAAABcy6WBNy4uTqdOndJTTz2l7OxstWvXTuvWrVNYWJgkKTs72+GevMXFxXr++ef13XffyWq1qm/fvtqyZYtatGhhn9OjRw+tXLlSTzzxhKZNm6ZWrVopNTVV3bp1q+nDAwAAQC3g8g+tJSQkKCEhocznUlJSHB63bdtWGRkZV9zniBEjNGLEiKooDwAAAG7O5V8tDAAAAFQnAi8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1lwfexYsXKzw8XL6+voqKitKmTZsuO3/FihXq0KGD/P39FRISorFjx+rUqVP251NSUmSxWJx+Lly4UN2HAgAAgFrIpYE3NTVVkyZN0tSpU5WRkaFevXpp4MCBysrKKnP+5s2bdd9992ncuHHau3ev3nnnHW3fvl3jx493mBcQEKDs7GyHH19f35o4JAAAANQyLg288+bN07hx4zR+/Hi1bdtWycnJCg0N1ZIlS8qc/9VXX6lFixaaOHGiwsPDdfPNN+vBBx/Ujh07HOZZLBYFBwc7/AAAAOB/k5erFi4sLNTOnTs1ZcoUh/HY2Fht2bKlzG169OihqVOnat26dRo4cKBOnjypVatWafDgwQ7zzp07p7CwMBUXF6tjx46aNWuWIiMjL1lLQUGBCgoK7I/z8vIkSTabTTabrbKHWG6la9TEWqge9ND90UP3Rw/dG/0zg4uxsqioSDXRxor8rrgs8Obm5qq4uFhBQUEO40FBQcrJySlzmx49emjFihWKi4vThQsXVFRUpKFDh+qFF16wz2nTpo1SUlJ00003KS8vTwsWLFDPnj21e/dutW7dusz9zp49WzNnznQaT0tLk7+//1UcZcWkp6fX2FqoHvTQ/dFD90cP3Rv9c19FRYMkWbV582YdOpRf7evl55d/DYthGEY11nJJJ06cUNOmTbVlyxZFR0fbx5955hm9+eab+vbbb5222bdvn/r376/JkydrwIABys7O1uOPP64uXbpo6dKlZa5TUlKiTp06qXfv3lq4cGGZc8o6wxsaGqrc3FwFBARc5ZFemc1mU3p6umJiYmS1Wqt9PVQ9euj+6KH7o4fujf65v4YNvXT2rEV79pzXDTdU/znVvLw8NWrUSL/++usV85rLzvA2atRInp6eTmdzT5486XTWt9Ts2bPVs2dPPf7445Kk9u3bq06dOurVq5eefvpphYSEOG3j4eGhLl266Pvvv79kLT4+PvLx8XEat1qtNfpHV9ProerRQ/dHD90fPXRv9M+dXTyH6uXlVSM9rMgaLvvQmre3t6KiopzeukhPT1ePHj3K3CY/P18eHo4le3p6SpIudaLaMAxlZmaWGYYBAABgfi47wytJiYmJio+PV+fOnRUdHa1XXnlFWVlZmjBhgiQpKSlJx48f1xtvvCFJGjJkiO6//34tWbLEfknDpEmT1LVrVzVp0kSSNHPmTHXv3l2tW7dWXl6eFi5cqMzMTC1atMhlxwkAAADXcWngjYuL06lTp/TUU08pOztb7dq107p16xQWFiZJys7Odrgn75gxY3T27Fm9+OKLevTRR1W/fn3169dPc+bMsc85c+aMHnjgAeXk5CgwMFCRkZH64osv1LVr1xo/PgAAALieSwOvJCUkJCghIaHM51JSUpzGHn74YT388MOX3N/8+fM1f/78qioPAAAAbs7lXy0MAAAAVCcCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMLVKfdPab7/9pmeffVb/+c9/dPLkSZWUlDg8f/jw4SopDgAAALhalQq848eP18aNGxUfH6+QkBBZLJaqrgsAAACoEpUKvB9//LE++ugj9ezZs6rrAQAAAKpUpa7hveaaa9SgQYOqrgUAAACocpUKvLNmzdL06dOVn59f1fUAAAAAVapSlzQ8//zzOnTokIKCgtSiRQtZrVaH53ft2lUlxQEAAABXq1KBd/jw4VVcBgAAAFA9KhV4Z8yYUdV1AAAAANWiUoG31M6dO7V//35ZLBZFREQoMjKyquoCAAAAqkSlAu/Jkyd199136/PPP1f9+vVlGIZ+/fVX9e3bVytXrtS1115b1XUCAAAAlVKpuzQ8/PDDysvL0969e/XLL7/o9OnT+u9//6u8vDxNnDixqmsEAAAAKq1SZ3g/+eQTbdiwQW3btrWPRUREaNGiRYqNja2y4gAAAICrVakzvCUlJU63IpMkq9WqkpKSqy4KAAAAqCqVCrz9+vXTI488ohMnTtjHjh8/rsmTJ+vWW2+tsuIAAACAq1WpwPviiy/q7NmzatGihVq1aqXrrrtO4eHhOnv2rF544YWqrhEAAACotEpdwxsaGqpdu3YpPT1d3377rQzDUEREhPr371/V9QEAAABX5aruwxsTE6OYmJiqqgUAAACocuUOvAsXLtQDDzwgX19fLVy48LJzuTUZAAAAaotyB9758+dr1KhR8vX11fz58y85z2KxEHgBAABQa5Q78B45cqTM/w0AAADUZpW6S8MfFRcXKzMzU6dPn66K3QEAAABVplKBd9KkSVq6dKmki2G3d+/e6tSpk0JDQ/X5559XZX0AAADAValU4F21apU6dOggSfrggw909OhRffvtt5o0aZKmTp1apQUCAAAAV6NSgTc3N1fBwcGSpHXr1umuu+7S9ddfr3HjxmnPnj1VWiAAAABwNSoVeIOCgrRv3z4VFxfrk08+sX/hRH5+vjw9Pau0QAAAAOBqVOqLJ8aOHauRI0cqJCREFovF/uUT27ZtU5s2baq0QAAAAOBqVCrwPvnkk2rXrp1+/PFH3XXXXfLx8ZEkeXp6asqUKVVaIAAAAHA1Kv3VwiNGjHAaGz169FUVAwAAAFQ1vloYAAAApsZXCwMAAMDU+GphAAAAmFqVfLUwAAAAUFtVKvCOGDFCzz77rNP4P//5T911111XXRQAAABQVSoVeDdu3KjBgwc7jd9222364osvrrooAAAAoKpUKvCeO3dO3t7eTuNWq1V5eXlXXRQAAABQVSoVeNu1a6fU1FSn8ZUrVyoiIuKqiwIAAACqSqUC77Rp0zRr1iyNHj1ar7/+ul5//XXdd999euaZZzRt2rQK7Wvx4sUKDw+Xr6+voqKitGnTpsvOX7FihTp06CB/f3+FhIRo7NixOnXqlMOc1atXKyIiQj4+PoqIiNCaNWsqfIwAAAAwh0oF3qFDh2rt2rU6ePCgEhIS9Oijj+rYsWPasGGDhg8fXu79pKamatKkSZo6daoyMjLUq1cvDRw4UFlZWWXO37x5s+677z6NGzdOe/fu1TvvvKPt27dr/Pjx9jlbt25VXFyc4uPjtXv3bsXHx2vkyJHatm1bZQ4VAAAAbq7SXy08ePDgMj+4VhHz5s3TuHHj7IE1OTlZ69ev15IlSzR79myn+V999ZVatGhh/2KL8PBwPfjgg5o7d659TnJysmJiYpSUlCRJSkpK0saNG5WcnKy33367zDoKCgpUUFBgf1x6HbLNZpPNZruqYyyP0jVqYi1UD3ro/uih+6OH7o3+mcHFWFlUVKSaaGNFflcqHXjPnDmjVatW6fDhw3rsscfUoEED7dq1S0FBQWratOkVty8sLNTOnTs1ZcoUh/HY2Fht2bKlzG169OihqVOnat26dRo4cKBOnjypVatWOQTvrVu3avLkyQ7bDRgwQMnJyZesZfbs2Zo5c6bTeFpamvz9/a94LFUlPT29xtZC9aCH7o8euj966N7on/sqKhokyarNmzfr0KH8al8vP7/8a1Qq8H7zzTfq37+/AgMDdfToUY0fP14NGjTQmjVr9MMPP+iNN9644j5yc3NVXFysoKAgh/GgoCDl5OSUuU2PHj20YsUKxcXF6cKFCyoqKtLQoUP1wgsv2Ofk5ORUaJ/SxbPAiYmJ9sd5eXkKDQ1VbGysAgICrngsV8tmsyk9PV0xMTGyWq3Vvh6qHj10f/TQ/dFD90b/3J+X18VYefPNN+uGGyp9TrXcKnJnsEpVk5iYqDFjxmju3LmqV6+efXzgwIG69957K7Qvi8Xi8NgwDKexUvv27dPEiRM1ffp0DRgwQNnZ2Xr88cc1YcIELV26tFL7lCQfHx/5+Pg4jVut1hr9o6vp9VD16KH7o4fujx66N/rnzgxJF4NvTfSwImtUKvBu375dL7/8stN406ZNL3sm9fcaNWokT09Pp/knT550OkNbavbs2erZs6cef/xxSVL79u1Vp04d9erVS08//bRCQkIUHBxcoX0CAADA3Cp1lwZfX98yTyN/9913uvbaa8u1D29vb0VFRTldq5Oenq4ePXqUuU1+fr48PBxL9vT0lHTxLK4kRUdHO+0zLS3tkvsEAACAuVUq8A4bNkxPPfWU/dNxFotFWVlZmjJliu68885y7ycxMVGvvfaali1bpv3792vy5MnKysrShAkTJF28tva+++6zzx8yZIjeffddLVmyRIcPH9aXX36piRMnqmvXrmrSpIkk6ZFHHlFaWprmzJmjb7/9VnPmzNGGDRs0adKkyhwqAAAA3FylLml47rnnNGjQIDVu3Fjnz59Xnz59lJOTo+joaD3zzDPl3k9cXJxOnTqlp556StnZ2WrXrp3WrVunsLAwSVJ2drbDPXnHjBmjs2fP6sUXX9Sjjz6q+vXrq1+/fpozZ459To8ePbRy5Uo98cQTmjZtmlq1aqXU1FR169atMocKAAAAN1epwBsQEKDNmzfr008/1a5du1RSUqJOnTqpf//+Fd5XQkKCEhISynwuJSXFaezhhx/Www8/fNl9jhgxQiNGjKhwLQAAADCfCgfeoqIi+fr6KjMzU/369VO/fv2qoy4AAACgSlT4Gl4vLy+FhYWpuLi4OuoBAAAAqlSlPrT2xBNPKCkpSb/88ktV1wMAAABUqUpdw7tw4UIdPHhQTZo0UVhYmOrUqePw/K5du6qkOAAAAOBqVSrwDh8+XBaLxX7vWwAAAKC2qlDgzc/P1+OPP661a9fKZrPp1ltv1QsvvKBGjRpVV30AAADAVanQNbwzZsxQSkqKBg8erHvuuUcbNmzQQw89VF21AQAAAFetQmd43333XS1dulR33323JGnUqFHq2bOniouL7V/xCwAAANQmFTrD++OPP6pXr172x127dpWXl5dOnDhR5YUBAAAAVaFCgbe4uFje3t4OY15eXioqKqrSogAAAICqUqFLGgzD0JgxY+Tj42Mfu3DhgiZMmOBwa7J333236ioEAAAArkKFAu/o0aOdxv785z9XWTEAAABAVatQ4F2+fHl11QEAAABUi0p9tTAAAADgLgi8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEzN5YF38eLFCg8Pl6+vr6KiorRp06ZLzh0zZowsFovTz4033mifk5KSUuacCxcu1MThAAAAoJZxaeBNTU3VpEmTNHXqVGVkZKhXr14aOHCgsrKyypy/YMECZWdn239+/PFHNWjQQHfddZfDvICAAId52dnZ8vX1rYlDAgAAQC3j0sA7b948jRs3TuPHj1fbtm2VnJys0NBQLVmypMz5gYGBCg4Otv/s2LFDp0+f1tixYx3mWSwWh3nBwcE1cTgAAACohbxctXBhYaF27typKVOmOIzHxsZqy5Yt5drH0qVL1b9/f4WFhTmMnzt3TmFhYSouLlbHjh01a9YsRUZGXnI/BQUFKigosD/Oy8uTJNlsNtlstvIeUqWVrlETa6F60EP3Rw/dHz10b/TPDC7GyqKiItVEGyvyu+KywJubm6vi4mIFBQU5jAcFBSknJ+eK22dnZ+vjjz/WW2+95TDepk0bpaSk6KabblJeXp4WLFignj17avfu3WrdunWZ+5o9e7ZmzpzpNJ6WliZ/f/8KHNXVSU9Pr7G1UD3oofujh+6PHro3+ue+iooGSbJq8+bNOnQov9rXy88v/xouC7ylLBaLw2PDMJzGypKSkqL69etr+PDhDuPdu3dX9+7d7Y979uypTp066YUXXtDChQvL3FdSUpISExPtj/Py8hQaGqrY2FgFBARU4Ggqx2azKT09XTExMbJardW+HqoePXR/9ND90UP3Rv/cn5fXxVh5880364Ybqj9ilr4jXx4uC7yNGjWSp6en09nckydPOp31/SPDMLRs2TLFx8fL29v7snM9PDzUpUsXff/995ec4+PjIx8fH6dxq9Vao390Nb0eqh49dH/00P3RQ/dG/9yZIeli8K2JHlZkDZd9aM3b21tRUVFOb12kp6erR48el91248aNOnjwoMaNG3fFdQzDUGZmpkJCQq6qXgAAALgnl17SkJiYqPj4eHXu3FnR0dF65ZVXlJWVpQkTJki6eKnB8ePH9cYbbzhst3TpUnXr1k3t2rVz2ufMmTPVvXt3tW7dWnl5eVq4cKEyMzO1aNGiGjkmAAAA1C4uDbxxcXE6deqUnnrqKWVnZ6tdu3Zat26d/a4L2dnZTvfk/fXXX7V69WotWLCgzH2eOXNGDzzwgHJychQYGKjIyEh98cUX6tq1a7UfDwAAAGofl39oLSEhQQkJCWU+l5KS4jQWGBh42U/lzZ8/X/Pnz6+q8gAAAODmXP7VwgAAAEB1IvACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTc3ngXbx4scLDw+Xr66uoqCht2rTpknPHjBkji8Xi9HPjjTc6zFu9erUiIiLk4+OjiIgIrVmzproPAwAAALWUSwNvamqqJk2apKlTpyojI0O9evXSwIEDlZWVVeb8BQsWKDs72/7z448/qkGDBrrrrrvsc7Zu3aq4uDjFx8dr9+7dio+P18iRI7Vt27aaOiwAAADUIi4NvPPmzdO4ceM0fvx4tW3bVsnJyQoNDdWSJUvKnB8YGKjg4GD7z44dO3T69GmNHTvWPic5OVkxMTFKSkpSmzZtlJSUpFtvvVXJyck1dFQAAACoTbxctXBhYaF27typKVOmOIzHxsZqy5Yt5drH0qVL1b9/f4WFhdnHtm7dqsmTJzvMGzBgwGUDb0FBgQoKCuyP8/LyJEk2m002m61ctVyN0jVqYi1UD3ro/uih+6OH7o3+mcHFWFlUVKSaaGNFfldcFnhzc3NVXFysoKAgh/GgoCDl5ORccfvs7Gx9/PHHeuuttxzGc3JyKrzP2bNna+bMmU7jaWlp8vf3v2ItVSU9Pb3G1kL1oIfujx66P3ro3uif+yoqGiTJqs2bN+vQofxqXy8/v/xruCzwlrJYLA6PDcNwGitLSkqK6tevr+HDh1/1PpOSkpSYmGh/nJeXp9DQUMXGxiogIOCKtVwtm82m9PR0xcTEyGq1Vvt6qHr00P3RQ/dHD90b/XN/Xl4XY+XNN9+sG26o/ohZ+o58ebgs8DZq1Eienp5OZ15PnjzpdIb2jwzD0LJlyxQfHy9vb2+H54KDgyu8Tx8fH/n4+DiNW63WGv2jq+n1UPXoofujh+6PHro3+ufODEkXg29N9LAia7jsQ2ve3t6KiopyeusiPT1dPXr0uOy2Gzdu1MGDBzVu3Din56Kjo532mZaWdsV9AgAAwJxceklDYmKi4uPj1blzZ0VHR+uVV15RVlaWJkyYIOnipQbHjx/XG2+84bDd0qVL1a1bN7Vr185pn4888oh69+6tOXPmaNiwYXrvvfe0YcMGbd68uUaOCQAAALWLSwNvXFycTp06paeeekrZ2dlq166d1q1bZ7/rQnZ2ttM9eX/99VetXr1aCxYsKHOfPXr00MqVK/XEE09o2rRpatWqlVJTU9WtW7dqPx4AAADUPi7/0FpCQoISEhLKfC4lJcVpLDAw8IqfyhsxYoRGjBhRFeUBAADAzbn8q4UBAACA6kTgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReAEAAGBqBF4AAACYGoEXAAAApubywLt48WKFh4fL19dXUVFR2rRp02XnFxQUaOrUqQoLC5OPj49atWqlZcuW2Z9PSUmRxWJx+rlw4UJ1HwoAAABqIS9XLp6amqpJkyZp8eLF6tmzp15++WUNHDhQ+/btU/PmzcvcZuTIkfrpp5+0dOlSXXfddTp58qSKiooc5gQEBOi7775zGPP19a224wAAAEDt5dLAO2/ePI0bN07jx4+XJCUnJ2v9+vVasmSJZs+e7TT/k08+0caNG3X48GE1aNBAktSiRQuneRaLRcHBweWuo6CgQAUFBfbHeXl5kiSbzSabzVaRQ6qU0jVqYi1UD3ro/uih+6OH7o3+mcHFWFlUVKSaaGNFfldcFngLCwu1c+dOTZkyxWE8NjZWW7ZsKXOb999/X507d9bcuXP15ptvqk6dOho6dKhmzZolPz8/+7xz584pLCxMxcXF6tixo2bNmqXIyMhL1jJ79mzNnDnTaTwtLU3+/v6VPMKKS09Pr7G1UD3oofujh+6PHro3+ue+iooGSbJq8+bNOnQov9rXy88v/xouC7y5ubkqLi5WUFCQw3hQUJBycnLK3Obw4cPavHmzfH19tWbNGuXm5iohIUG//PKL/TreNm3aKCUlRTfddJPy8vK0YMEC9ezZU7t371br1q3L3G9SUpISExPtj/Py8hQaGqrY2FgFBARU0RFfms1mU3p6umJiYmS1Wqt9PVQ9euj+6KH7o4fujf65Py+vi7Hy5ptv1g03VH/ELH1HvjxcekmDdPHyg98zDMNprFRJSYksFotWrFihwMBASRcvixgxYoQWLVokPz8/de/eXd27d7dv07NnT3Xq1EkvvPCCFi5cWOZ+fXx85OPj4zRutVpr9I+uptdD1aOH7o8euj966N7onzszJF0MvjXRw4qs4bK7NDRq1Eienp5OZ3NPnjzpdNa3VEhIiJo2bWoPu5LUtm1bGYahY8eOlbmNh4eHunTpou+//77qigcAAIDbcFng9fb2VlRUlNO1Ounp6erRo0eZ2/Ts2VMnTpzQuXPn7GMHDhyQh4eHmjVrVuY2hmEoMzNTISEhVVc8AAAA3IZL78ObmJio1157TcuWLdP+/fs1efJkZWVlacKECZIuXlt733332effe++9atiwocaOHat9+/bpiy++0OOPP66//OUv9g+tzZw5U+vXr9fhw4eVmZmpcePGKTMz075PAAAA/G9x6TW8cXFxOnXqlJ566illZ2erXbt2WrduncLCwiRJ2dnZysrKss+vW7eu0tPT9fDDD6tz585q2LChRo4cqaeffto+58yZM3rggQeUk5OjwMBARUZG6osvvlDXrl1r/PgAAADgei7/0FpCQoISEhLKfC4lJcVprE2bNpe9Zcn8+fM1f/78qioPAAAAbs7lXy0MAAAAVCcCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABTI/ACAADA1Ai8AAAAMDUCLwAAAEyNwAsAAABT83J1Ae7KMAwVFRWpuLj4qvdls9nk5eWlCxcuVMn+UPPooTNPT095eXnJYrG4uhQAwP84Am8lFBYWKjs7W/n5+VWyP8MwFBwcrB9//JFw4KboYdn8/f0VEhIib29vV5cCAPgfRuCtoJKSEh05ckSenp5q0qSJvL29rzrglJSU6Ny5c6pbt648PLjKxB3RQ0eGYaiwsFA///yzjhw5otatW/O6AABchsBbQYWFhSopKVFoaKj8/f2rZJ8lJSUqLCyUr68vocBN0UNnfn5+slqt+uGHH+yvDQAArsB/mSuJUANcGX8nAIDagP8aAQAAwNQIvAAAADA1Ai+qXYsWLZScnFzlc83AYrFo7dq1kqSjR4/KYrEoMzPTpTUBAGA2BN7/IWPGjJHFYpHFYpHValXLli312GOP6bfffqvWdbdv364HHnigyudejVtuucX+Wnh7e6tVq1ZKSkpSQUFBta99tQ4ePKixY8eqWbNm8vHxUXh4uO655x7t2LHD1aUBAFArEXj/x9x2223Kzs7W4cOH9fTTT2vx4sV67LHHypxrs9mqZM1rr7223He0qMjcq3X//fcrOztbBw8e1Ny5c7Vo0SI9+eSTNbJ2Ze3YsUNRUVE6cOCAXn75Ze3bt09r1qxRmzZt9Oijj1Z6v8XFxSopKanCSgEAqD0IvFXAMKTffnPNj2FUrFYfHx8FBwcrNDRU9957r0aNGmV/S/3JJ59Ux44dtWzZMrVs2VI+Pj4yDEO//vqrHnjgATVu3FgBAQHq16+fdu/e7bDf999/X507d5avr68aNWqkO+64w/7cHy9TePLJJ9W8eXP5+PioSZMmmjhx4iXnZmVladiwYapbt64CAgI0cuRI/fTTTw776tixo9588021aNFCgYGBuvvuu3X27Nkrvhb+/v4KDg5W8+bNdeeddyomJkZpaWn25w3D0Ny5c9WyZUv5+fmpQ4cOWrVqlcM+9u7dq8GDB6t+/foKDQ1Vnz59dOjQIUkXz1bHxMSoUaNGCgwMVJ8+fbRr164r1nUphmFozJgxat26tTZt2qTBgwerVatW6tixo2bMmKH33ntPkvT555/LYrHozJkz9m0zMzNlsVh09OhRSVJKSorq16+vDz/8UBEREfLx8dGrr74qX19fh+0kaeLEierTp4/98ZYtW9S7d2/5+fkpNDRUEydOrPZ3CQAAuBoE3iqQny/VrVv5n4AADzVrVl8BAR4V3vZqv+zNz8/P4UzuwYMH9e9//1urV6+2X0s6ePBg5eTkaN26ddq5c6c6deqkW2+9Vb/88osk6aOPPtIdd9yhwYMHKyMjQ//5z3/UuXPnMtdbtWqV5s+fr5dfflnff/+91q5dq5tuuqnMuYZhaPjw4frll1+0ceNGpaen69ChQ4qLi3OYd+jQIa1du1YffvihPvzwQ23cuFHPPvtshV6H3bt368svv5TVarWPPfHEE1q+fLmWLFmivXv3avLkyfrzn/+sjRs3SpKOHz+u3r17y9fXVxs2bNBnn32mMWPGqKioSJJ09uxZjR49Wps2bdJXX32l1q1ba9CgQeUK42XJzMzU3r179eijj5Z5u6/69etXaH/5+fmaPXu2XnvtNe3du1d//vOfVb9+fa1evdo+p7i4WP/+9781atQoSdKePXs0YMAA3XHHHfrmm2+UmpqqzZs3629/+1uljgkAgBphwMmvv/5qSDJ+/fVXp+fOnz9v7Nu3zzh//rx97Nw5w7h4rrXmf86dK/9xjR492hg2bJj98bZt24yGDRsaI0eONAzDMGbMmGFYrVbj5MmT9jn/+c9/jICAAOPChQsO+2rVqpXx8ssvG4ZhGNHR0caoUaMuuW5YWJgxf/58wzAM4/nnnzeuv/56o7Cw8Ipz09LSDE9PTyMrK8v+/N69ew1Jxtdff22v2d/f38jLy7PPefzxx41u3bpd9rXo06ePYbVajTp16hje3t6GJMPDw8NYtWqVYRiGce7cOcPX19fYsmWLw3bjxo0z7rnnHsMwDCMpKckIDw83CgsLjeLiYuP06dNGcXHxJdcsKioy6tWrZ3zwwQf2MUnGmjVrDMMwjCNHjhiSjIyMjDK3T01NNSQZu3btuuyxffbZZ4Yk4/Tp0/axjIwMQ5Jx5MgRwzAMY/ny5YYkIzMz02HbiRMnGv369bM/Xr9+veHt7W388ssvhmEYRnx8vPHAAw84bLNp0ybDw8PD4W+iVFl/L7VVYWGhsXbt2kv+bqL2o4fujf65v/79i422bXONI0dqpoeXy2t/xDetVQF/f+ncucpvX1JSory8PAUEBFT4Rv0Vvdz1ww8/VN26dVVUVCSbzaZhw4bphRdesD8fFhama6+91v54586dOnfunBo2bOiwn/Pnz9vfus/MzNT9999frvXvuusuJScnq2XLlrrttts0aNAgDRkyRF5ezr+K+/fvV2hoqEJDQ+1jERERql+/vvbv368uXbpIungZRL169exzQkJCdPLkSUnSihUr9OCDD9qf+/jjj9WrVy9J0qhRozR16lTl5eVpzpw5CggI0J133ilJ2rdvny5cuKCYmBiHmgoLCxUZGWk/7l69eslqtZZ5/evJkyc1ffp0ffrpp/rpp59UXFys/Px8ZWVlleu1+iPj/3/9ytV+lXUpb29vtW/f3mFs1KhRio6O1okTJ9SkSROtWLFCgwYN0jXXXCPp4u/DwYMHtWLFCoe6Sr9yu23btlVSGwDA/axbV6x16zaradNBri7FCYG3ClgsUp06ld++pEQqLr64j+r+Yqq+fftqyZIlslqtatKkicNb+JJU5w8HUlJSopCQEH3++edO+yp9C93Pz6/c64eGhuq7775Tenq6NmzYoISEBP3zn//Uxo0bnWoxDKPMcPfH8T9uZ7FY7AF06NCh6tatm/25pk2b2v93YGCgrrvuOknSv/71L914441aunSpxo0bZ9/+o48+cthGungddHmOe8yYMfr555+VnJyssLAw+fj4KDo6WoWFhZfd7lKuv/56SRf/IdCxY8dLziv9R1NpQJbK/gCin5+f0+vbtWtXtWrVSitXrtRDDz2kNWvWaPny5fbnS0pK9OCDDzpcd12qefPmFToeAABqCoH3f0ydOnXsIa88OnXqpJycHHl5ealFixZlzmnfvr3+85//aOzYseXap5+fn4YOHaqhQ4fqr3/9q9q0aaM9e/aoU6dODvMiIiKUlZWlH3/80X6Wd9++ffr111/LfSaxXr16Dmd/L8Vqtervf/+7kpKSdM8999g/yJWVleXwga3fa9++vV5//XXZbDZ5eno6Pb9p0yYtXrxYgwZd/Jfujz/+qNzc3HLVXZaOHTsqIiJCzz//vOLi4pzeDThz5ozq169vP0OfnZ1tPzNbkXv73nvvvVqxYoWaNWsmDw8PDR482P5cp06dtHfv3gr9DgEA4Gp8aA2X1b9/f0VHR2v48OFav369jh49qi1btuiJJ56w3/d1xowZevvttzVjxgzt379fe/bs0dy5c8vcX0pKipYuXar//ve/Onz4sN588035+fkpLCyszLXbt2+vUaNGadeuXfr666913333qU+fPpf8UNzVuPfee2WxWLR48WLVq1dPjz32mCZPnqzXX39dhw4dUkZGhhYtWqTXX39dkvS3v/1NeXl5uvvuu7Vjxw4dOnRIb775pr777jtJ0nXXXac333xT+/fv17Zt2zRq1KgKnQ3/I4vFouXLl+vAgQPq3bu31q1bp8OHD+ubb77RM888o2HDhtnXDQ0N1ZNPPqkDBw7oo48+0vPPP1/udUpf72eeeUYjRoyQr6+v/bn/7//7/7R161b99a9/VWZmpr7//nu9//77evjhhyt9XAAAVDcCLy7LYrFo3bp16t27t/7yl7/o+uuv1913362jR48qKChI0sUvcXjnnXf0/vvvq2PHjurXr5+2bdtW5v7q16+vV199VT179rSfGf7ggw+crhEuXXvt2rW65ppr1Lt3b/Xv318tW7ZUampqtRyrt7e3/va3v2nu3Lk6d+6cZs2apenTp2v27Nlq27atBgwYoA8++EDh4eGSpIYNG+rTTz/VuXPn1LdvX/Xt21dLly61X2KxbNkynT59WpGRkYqPj9fEiRPVuHHjq6qxa9eu2rFjh1q1aqX7779fbdu21dChQ7V371777dysVqvefvttffvtt+rQoYPmzJmjp59+utxrtG7dWl26dNE333xjvztDqfbt22vjxo36/vvv1atXL0VGRmratGkKCQm5quMCAKA6WYzfX+gHSVJeXp4CAwP166+/KiAgwOG5Cxcu6MiRIwoPD3c483U1ruZDa6gd6GHZquPvpbrYbDatW7dOgwYNcrouHO6BHro3+uf+arqHl8trf8R/mQEAAGBqBF4AAACYGoEXAAAApkbgBQAAgKkReCuJz/oBV8bfCQCgNiDwVlDppw7z8/NdXAlQ+5X+nfCJawCAK/FNaxXk6emp+vXr6+TJk5Ikf3//Mr/+tiJKSkpUWFioCxcucEsrN0UPHRmGofz8fJ08eVL169cv85voAACoKQTeSggODpYke+i9WoZh6Pz58/Lz87vq8AzXoIdlq1+/vv3vBQAAVyHwVoLFYlFISIgaN24sm8121fuz2Wz64osv1Lt3b976dVP00JnVauXMLgCgViDwXgVPT88q+Q+6p6enioqK5OvrS1hyU/QQAIDai4sNAQAAYGoEXgAAAJgagRcAAACmxjW8ZSi9WX5eXl6NrGez2ZSfn6+8vDyu/3RT9ND90UP3Rw/dG/1zfzXdw9KcVp4vOSLwluHs2bOSpNDQUBdXAgAAgMs5e/asAgMDLzvHYvDdn05KSkp04sQJ1atXr0buqZqXl6fQ0FD9+OOPCggIqPb1UPXoofujh+6PHro3+uf+arqHhmHo7NmzatKkyRW/9IkzvGXw8PBQs2bNanzdgIAA/sjdHD10f/TQ/dFD90b/3F9N9vBKZ3ZL8aE1AAAAmBqBFwAAAKZG4K0FfHx8NGPGDPn4+Li6FFQSPXR/9ND90UP3Rv/cX23uIR9aAwAAgKlxhhcAAACmRuAFAACAqRF4AQAAYGoEXgAAAJgagbeGLF68WOHh4fL19VVUVJQ2bdp02fkbN25UVFSUfH191bJlS7300ks1VCkupSI9fPfddxUTE6Nrr71WAQEBio6O1vr162uwWpSlon+Hpb788kt5eXmpY8eO1VsgLqui/SsoKNDUqVMVFhYmHx8ftWrVSsuWLauhalGWivZwxYoV6tChg/z9/RUSEqKxY8fq1KlTNVQt/uiLL77QkCFD1KRJE1ksFq1du/aK29SaPGOg2q1cudKwWq3Gq6++auzbt8945JFHjDp16hg//PBDmfMPHz5s+Pv7G4888oixb98+49VXXzWsVquxatWqGq4cpSraw0ceecSYM2eO8fXXXxsHDhwwkpKSDKvVauzatauGK0epivaw1JkzZ4yWLVsasbGxRocOHWqmWDipTP+GDh1qdOvWzUhPTzeOHDlibNu2zfjyyy9rsGr8XkV7uGnTJsPDw8NYsGCBcfjwYWPTpk3GjTfeaAwfPryGK0epdevWGVOnTjVWr15tSDLWrFlz2fm1Kc8QeGtA165djQkTJjiMtWnTxpgyZUqZ8//v//7PaNOmjcPYgw8+aHTv3r3aasTlVbSHZYmIiDBmzpxZ1aWhnCrbw7i4OOOJJ54wZsyYQeB1oYr27+OPPzYCAwONU6dO1UR5KIeK9vCf//yn0bJlS4exhQsXGs2aNau2GlF+5Qm8tSnPcElDNSssLNTOnTsVGxvrMB4bG6stW7aUuc3WrVud5g8YMEA7duyQzWartlpRtsr08I9KSkp09uxZNWjQoDpKxBVUtofLly/XoUOHNGPGjOouEZdRmf69//776ty5s+bOnaumTZvq+uuv12OPPabz58/XRMn4g8r0sEePHjp27JjWrVsnwzD0008/adWqVRo8eHBNlIwqUJvyjFeNrvY/KDc3V8XFxQoKCnIYDwoKUk5OTpnb5OTklDm/qKhIubm5CgkJqbZ64awyPfyj559/Xr/99ptGjhxZHSXiCirTw++//15TpkzRpk2b5OXF/6t0pcr07/Dhw9q8ebN8fX21Zs0a5ebmKiEhQb/88gvX8bpAZXrYo0cPrVixQnFxcbpw4YKKioo0dOhQvfDCCzVRMqpAbcoznOGtIRaLxeGxYRhOY1eaX9Y4ak5Fe1jq7bff1pNPPqnU1FQ1bty4uspDOZS3h8XFxbr33ns1c+ZMXX/99TVVHq6gIn+DJSUlslgsWrFihbp27apBgwZp3rx5SklJ4SyvC1Wkh/v27dPEiRM1ffp07dy5U5988omOHDmiCRMm1ESpqCK1Jc9w2qKaNWrUSJ6enk7/gj158qTTv3pKBQcHlznfy8tLDRs2rLZaUbbK9LBUamqqxo0bp3feeUf9+/evzjJxGRXt4dmzZ7Vjxw5lZGTob3/7m6SLAcowDHl5eSktLU39+vWrkdpRub/BkJAQNW3aVIGBgfaxtm3byjAMHTt2TK1bt67WmuGoMj2cPXu2evbsqccff1yS1L59e9WpU0e9evXS008/zbudbqA25RnO8FYzb29vRUVFKT093WE8PT1dPXr0KHOb6Ohop/lpaWnq3LmzrFZrtdWKslWmh9LFM7tjxozRW2+9xTVnLlbRHgYEBGjPnj3KzMy0/0yYMEE33HCDMjMz1a1bt5oqHarc32DPnj114sQJnTt3zj524MABeXh4qFmzZtVaL5xVpof5+fny8HCMKZ6enpL+31lC1G61Ks/U+Mfk/geV3opl6dKlxr59+4xJkyYZderUMY4ePWoYhmFMmTLFiI+Pt88vvY3H5MmTjX379hlLly7ltmQuVtEevvXWW4aXl5exaNEiIzs72/5z5swZVx3C/7yK9vCPuEuDa1W0f2fPnjWaNWtmjBgxwti7d6+xceNGo3Xr1sb48eNddQj/8yraw+XLlxteXl7G4sWLjUOHDhmbN282OnfubHTt2tVVh/A/7+zZs0ZGRoaRkZFhSDLmzZtnZGRk2G8tV5vzDIG3hixatMgICwszvL29jU6dOhkbN260Pzd69GijT58+DvM///xzIzIy0vD29jZatGhhLFmypIYrxh9VpId9+vQxJDn9jB49uuYLh11F/w5/j8DrehXt3/79+43+/fsbfn5+RrNmzYzExEQjPz+/hqvG71W0hwsXLjQiIiIMPz8/IyQkxBg1apRx7NixGq4apT777LPL/retNucZi2HwvgAAAADMi2t4AQAAYGoEXgAAAJgagRcAAACmRuAFAACAqRF4AQAAYGoEXgAAAJgagRcAAACmRuAFAACAqRF4AQCX1aJFCyUnJ9sfWywWrV271mX1AEBFEXgBoBYbM2aMLBaLLBaLvLy81Lx5cz300EM6ffq0q0sDALdB4AWAWu62225Tdna2jh49qtdee00ffPCBEhISXF0WALgNAi8A1HI+Pj4KDg5Ws2bNFBsbq7i4OKWlpdmfX758udq2bStfX1+1adNGixcvdtj+2LFjuvvuu9WgQQPVqVNHnTt31rZt2yRJhw4d0rBhwxQUFKS6deuqS5cu2rBhQ40eHwBUNy9XFwAAKL/Dhw/rk08+kdVqlSS9+uqrmjFjhl588UVFRkYqIyND999/v+rUqaPRo0fr3Llz6tOnj5o2bar3339fwcHB2rVrl0pKSiRJ586d06BBg/T000/L19dXr7/+uoYMGaLvvvtOzZs3d+WhAkCVIfACQC334Ycfqm7duiouLtaFCxckSfPmzZMkzZo1S88//7zuuOMOSVJ4eLj27dunl19+WaNHj9Zbb72ln3/+Wdu3b1eDBg0kSdddd5193x06dFCHDh3sj59++mmtWbNG77//vv72t7/V1CECQLUi8AJALde3b18tWbJE+fn5eu2113TgwAE9/PDD+vnnn/Xjjz9q3Lhxuv/+++3zi4qKFBgYKEnKzMxUZGSkPez+0W+//aaZM2fqww8/1IkTJ1RUVKTz588rKyurRo4NAGoCgRcAark6derYz8ouXLhQffv21cyZM+1nYF999VV169bNYRtPT09Jkp+f32X3/fjjj2v9+vV67rnndN1118nPz08jRoxQYWFhNRwJALgGgRcA3MyMGTM0cOBAPfTQQ2ratKkOHz6sUaNGlTm3ffv2eu211/TLL7+UeZZ306ZNGjNmjP70pz9JunhN79GjR6uzfACocdylAQDczC233KIbb7xR//jHP/Tkk09q9uzZWrBggQ4cOKA9e/Zo+fLl9mt877nnHgUHB2v48OH68ssvdfjwYa1evVpbt26VdPF63nfffVeZmZnavXu37r33XvsH2gDALAi8AOCGEhMT9eqrr2rAgAF67bXXlJKSoptuukl9+vRRSkqKwsPDJUne3t5KS0tT48aNNWjQIN1000169tln7Zc8zJ8/X9dcc4169OihIUOGaMCAAerUqZMrDw0AqpzFMAzD1UUAAAAA1YUzvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAUyPwAgAAwNQIvAAAADA1Ai8AAABMjcALAAAAU/v/AcfL77ADtos7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', label='Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964bfb91-3ed8-4983-9b2f-b7aa14d83aeb",
   "metadata": {},
   "source": [
    "Question21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare \n",
    "their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "949da077-f724-4bf2-a9b5-ad9fef34434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with solver 'liblinear': 95.61%\n",
      "Accuracy with solver 'saga': 97.37%\n",
      "Accuracy with solver 'lbfgs': 95.61%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names) \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "solvers = ['liblinear', 'saga', 'lbfgs']\n",
    "accuracies = {}\n",
    "\n",
    "\n",
    "for solver in solvers:\n",
    "    \n",
    "    logreg = LogisticRegression(solver=solver, max_iter=10000)\n",
    "    \n",
    "    \n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "   \n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies[solver] = accuracy\n",
    "\n",
    "\n",
    "for solver, accuracy in accuracies.items():\n",
    "    print(f\"Accuracy with solver '{solver}': {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99cbfe6-f697-4910-8839-c1155faa6bc1",
   "metadata": {},
   "source": [
    "Question22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews \n",
    "Correlation Coefficient (MCCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6ffca00-111a-4cb0-a1c1-b6adffa2bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient (MCC): 0.9068\n",
      "Accuracy: 95.61%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9c4d3-689b-434d-8e84-7f3b360b9ec6",
   "metadata": {},
   "source": [
    "Question23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their \n",
    "accuracy to see the impact of feature scalinM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0292499-f64f-414e-88cc-c854f44ffe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on raw data: 95.61%\n",
      "Accuracy on standardized data: 97.37%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg_raw = LogisticRegression(max_iter=10000)\n",
    "logreg_raw.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_raw = logreg_raw.predict(X_test)\n",
    "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "logreg_scaled = LogisticRegression(max_iter=10000)\n",
    "logreg_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred_scaled = logreg_scaled.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "\n",
    "\n",
    "print(f\"Accuracy on raw data: {accuracy_raw * 100:.2f}%\")\n",
    "print(f\"Accuracy on standardized data: {accuracy_scaled * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2befd371-cff0-4ce5-a01f-260034947549",
   "metadata": {},
   "source": [
    "Question24.Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using \n",
    "cross-validatioM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd1c51b3-f144-4953-beb2-b3c380c8082a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C: 100\n",
      "Test set accuracy with optimal C: 95.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_C = grid_search.best_params_['C']\n",
    "print(f\"Optimal C: {best_C}\")\n",
    "\n",
    "\n",
    "best_logreg = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_logreg.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test set accuracy with optimal C: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa52cb11-7b10-48a6-baee-b635ab840d8e",
   "metadata": {},
   "source": [
    "Question25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3303f5ef-a252-425c-b321-f4746e16b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Model loaded successfully!\n",
      "Accuracy of the loaded model: 95.61%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib  \n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  \n",
    "y = data.target  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "joblib.dump(logreg, 'logreg_model.joblib')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "\n",
    "loaded_model = joblib.load('logreg_model.joblib')\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the loaded model: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
