{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb92995-dea6-4334-9fb9-c3e3c352eccb",
   "metadata": {},
   "source": [
    "1. Explain the properties of the F-distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b8bfd-d2c1-413c-89b2-873325dede28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "\n",
    "Key properties of the F-distribution:\n",
    "1.Definition: The F-distribution is the distribution of the ratio of two scaled chi-squared \n",
    "distributions.Specifically, if X and Y are independent chi-squared random variables with d1 and d2 degrees of freedom, respectively, then the random variable F= (X/d1)/((Y/d2)\n",
    "2.Shape: The F-distribution is positively skewed and its shape depends on the degrees of freedom. As the degrees of freedom increase, the distribution becomes more symmetric and approaches a normal distribution.\n",
    "3.Degrees of Freedom: The F-distribution is characterized by two sets of degrees of freedom:\n",
    "d1: associated with the numerator (related to the variance estimate of the group means).\n",
    "d2: associated with the denominator (related to the variance estimate of the error or residuals).\n",
    "4.Range: The F-distribution takes only positive values, ranging from 0 to infinity.\n",
    "5.Critical Values: The F-distribution is used to determine critical values for hypothesis tests involving variance ratios. The critical values can be obtained from F-distribution tables or calculated using statistical software.\n",
    "6.Applications: The F-distribution is primarily used in hypothesis testing, particularly for:\n",
    "Comparing variances across different groups.\n",
    "Conducting ANOVA to test if there are any statistically significant differences between the means of three or more independent groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac4efb-2fad-4f5f-9f0e-c516085e9e8b",
   "metadata": {},
   "source": [
    "2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deabf1e1-87af-40ef-be39-1ec07fa44520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "\n",
    "The F-distribution is primarily used in several types of statistical tests, particularly in the context of variance \n",
    "analysis and regression. Here are the main types of tests that utilize the F-distribution and the reasons for its appropriateness:\n",
    "\n",
    "ANOVA (Analysis of Variance):\n",
    "Purpose: To compare the means of three or more groups to see if at least one group mean is different.\n",
    "Use of F-distribution: ANOVA tests the ratio of the variance between groups to the variance within groups. Under the null hypothesis (that all group means are equal), this ratio follows an F-distribution.\n",
    "\n",
    "Regression Analysis:\n",
    "Purpose: To assess the overall significance of a regression model and to compare models.\n",
    "Use of F-distribution: In the context of multiple regression, the F-test compares the explained variance by the model to the unexplained variance. The ratio of these variances follows an F-distribution under the null hypothesis that the predictors do not improve the model.\n",
    "\n",
    "Comparing Two Variances:\n",
    "Purpose: To determine if two population variances are equal.\n",
    "Use of F-distribution: The ratio of two sample variances (from normally distributed populations) follows an F-distribution, allowing for hypothesis testing about the equality of variances.\n",
    "\n",
    "F-distribution is Appropriate:\n",
    "Ratio of Variances: The F-distribution arises from the ratio of two independent chi-squared variables divided by their respective degrees of freedom. This makes it particularly suited for tests that compare variances.\n",
    "Non-negativity: Since variances are always non-negative, the F-distribution is defined only for positive values, which aligns with the nature of variance comparisons.\n",
    "Degrees of Freedom: The F-distribution has two parameters corresponding to the degrees of freedom of the numerator and denominator, allowing flexibility in modeling different situations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a9add7-2ca4-412a-9843-652869598a86",
   "metadata": {},
   "source": [
    "3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a954c05-4e26-4514-ab17-c2977d164032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "When conducting an F-test to compare the variances of two populations, several key assumptions must be met to ensure the validity of the results:\n",
    "\n",
    "Normality:\n",
    "Both populations should be normally distributed. The F-test is robust to deviations from normality, especially with larger sample sizes, but significant departures from normality can affect the results.\n",
    "\n",
    "Independence:\n",
    "The samples drawn from each population must be independent of each other. This means that the selection of one sample does not influence the selection of the other.\n",
    "\n",
    "Random Sampling:\n",
    "The samples should be obtained through a random sampling method from the respective populations. This helps ensure that the samples are representative.\n",
    "\n",
    "Homogeneity of Variances (in the context of other tests):\n",
    "While the F-test itself is used to assess the equality of variances, it is often assumed that the variances are similar in other related analyses (like ANOVA). This means that while you are testing for differences, the assumption of similar variances is a background consideration.\n",
    "\n",
    "Finite Variances:\n",
    "The variances of both populations should be finite. Infinite or undefined variances would make the F-test invalid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6593b-81a3-4d20-9c34-ca57b12f54f4",
   "metadata": {},
   "source": [
    "4. What is the purpose of ANOVA, and how does it differ from a t-test? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c8eca-e7df-4fc5-9cf5-662f7600e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "\n",
    "Purpose of ANOVA\n",
    "ANOVA (Analysis of Variance) is a statistical method used to determine whether there are significant differences \n",
    "between the means of three or more groups. Its primary purpose is to test the null hypothesis that all group \n",
    "means are equal against the alternative hypothesis that at least one group mean is different. ANOVA helps to identify \n",
    "whether the variation in group means is greater than would be expected by chance alone.\n",
    "\n",
    "Differences from a t-test\n",
    "Number of Groups:\n",
    "ANOVA: Used when comparing three or more groups.\n",
    "t-test: Used for comparing the means of two groups.\n",
    "\n",
    "Hypotheses:\n",
    "ANOVA: Tests the null hypothesis that all group means are equal \n",
    "t-test: Tests the null hypothesis that the means of two groups are equal \n",
    "\n",
    "Type of Output:\n",
    "ANOVA: Provides an F-statistic and p-value to determine if at least one group mean is significantly different from the others. If significant, post-hoc tests may be needed to identify which specific groups differ.\n",
    "t-test: Provides a t-statistic and p-value that directly indicate whether the two group means are significantly different.\n",
    "\n",
    "Assumptions:\n",
    "Both tests have similar assumptions regarding normality and independence, but ANOVA also assumes homogeneity of variances across groups, which is not a concern in a standard t-test since it only involves two groups.\n",
    "\n",
    "Data Structure:\n",
    "ANOVA: Typically requires a more complex data structure with multiple groups or levels (e.g., factorial designs).\n",
    "t-test: Generally applied to simpler datasets with two distinct groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcaad1-4bdb-407b-bca3-25a75591d618",
   "metadata": {},
   "source": [
    "5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a206031-fade-4d27-8f45-bc9541f79220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "\n",
    "When to Use One-Way ANOVA\n",
    "Comparing Three or More Groups: Use one-way ANOVA when you have three or more groups \n",
    "and you want to determine if there are any statistically significant differences among their means.\n",
    "\n",
    "Why Use One-Way ANOVA Instead of Multiple t-Tests\n",
    "Inflated Type I Error Rate:\n",
    "Conducting multiple t-tests increases the risk of making a Type I error (incorrectly rejecting the \n",
    "null hypothesis) because each test carries its own alpha level (e.g., 0.05). With each additional \n",
    "test, the cumulative probability of incorrectly finding at least one significant result increases. \n",
    "One-way ANOVA maintains a single overall alpha level for the entire analysis.\n",
    "\n",
    "Overall Comparison:\n",
    "One-way ANOVA tests the null hypothesis that all group means are equal in one step, providing an overall assessment of variance among groups. If the ANOVA result is significant, it indicates that at least one group differs from the others without specifying which ones.\n",
    "\n",
    "Efficiency:\n",
    "One-way ANOVA is more efficient than performing multiple t-tests because it consolidates the comparisons into a single analysis. This is particularly useful when dealing with many groups, as it reduces the number of tests needed and saves time.\n",
    "\n",
    "Post-Hoc Analysis:\n",
    "If the one-way ANOVA indicates significant differences, post-hoc tests (like Tukey's HSD) can be performed to identify specific group differences. This structured approach is more systematic than performing multiple t-tests.\n",
    "\n",
    "Assumptions:\n",
    "While both methods assume normality and independence, ANOVA is specifically designed to handle the variances across multiple groups, accounting for differences that t-tests cannot handle adequately when extended beyond two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68617cb2-a36c-4e3d-a365-3cac289335a9",
   "metadata": {},
   "source": [
    "6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance.\n",
    "How does this partitioning contribute to the calculation of the F-statistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d74ff79-ff67-446a-bcbd-6f1c79e96e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "\n",
    "In ANOVA (Analysis of Variance), the total variance observed in the data is partitioned into two components: \n",
    "between-group variance and within-group variance. This partitioning helps assess whether there are significant \n",
    "differences among group means.\n",
    "\n",
    "1. Variance Components\n",
    "Total Variance: This is the overall variability in the data and is calculated as the sum of squared deviations of each observation from the grand mean (the mean of all observations).\n",
    "Between-Group Variance: This measures the variability between the different groups. It reflects how much the group means deviate from the grand mean. If the groups have different means, this variance will be large.\n",
    "Within-Group Variance: This measures the variability within each group. It reflects how much the individual observations within each group deviate from their respective group mean\n",
    "\n",
    "2.Calculation of the F-statistic\n",
    "The F-statistic is used to determine whether the between-group variance is significantly greater than the within-group variance, \n",
    "indicating that at least one group mean is different from the others.\n",
    "F= Mean¬†Square¬†Within/Mean¬†Square¬†Between\n",
    " = Within-group¬†variance/Between-group¬†variance\n",
    "‚Äã\n",
    "Mean Square Between (MSB): This is the between-group variance divided by its degrees of freedom:\n",
    "MSB=Between-group¬†sum¬†of¬†squares/ùëî‚àí1\n",
    "\n",
    "Mean Square Within (MSW): This is the within-group variance divided by its degrees of freedom:\n",
    "\n",
    "MSW=Within-group¬†sum¬†of¬†squares/ùëÅ‚àíùëî\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02842668-3051-4f68-a9c6-47bbb2b1ebfe",
   "metadata": {},
   "source": [
    "7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fd5f7-2102-4a66-9726-6d2d8cdc92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "The classical (frequentist) approach to ANOVA and the Bayesian approach represent two different philosophies \n",
    "in statistical inference, particularly in how they handle uncertainty, parameter estimation, \n",
    "and hypothesis testing. Here are the key differences:\n",
    "\n",
    "1. Handling Uncertainty\n",
    "Frequentist Approach:\n",
    "a.Uncertainty is quantified through concepts such as confidence intervals and p-values. The focus is on long-run properties of estimators and tests based on repeated sampling.\n",
    "b.The parameters are considered fixed but unknown quantities, and the randomness comes from the data collected.\n",
    "\n",
    "Bayesian Approach:\n",
    "a.Uncertainty is expressed using probability distributions. Prior beliefs about parameters are combined with the observed data to produce posterior distributions.\n",
    "b.Parameters are treated as random variables, which allows for direct probabilistic statements about them.\n",
    "\n",
    "2. Parameter Estimation\n",
    "Frequentist Approach:\n",
    "a.Point estimates (e.g., means, variances) are obtained using methods like maximum likelihood estimation (MLE) or least squares.\n",
    "b.Confidence intervals provide a range of values for the parameter but do not express the probability of a parameter falling within a specific interval given the data.\n",
    "Bayesian Approach:\n",
    "a.Parameters are estimated through the posterior distribution, which combines prior information with the likelihood of the observed data.\n",
    "b.Credible intervals (the Bayesian analogue of confidence intervals) can be directly interpreted as the probability that the parameter lies within a certain range given the data.\n",
    "\n",
    "3. Hypothesis Testing\n",
    "Frequentist Approach:\n",
    "a.Hypothesis tests (e.g., ANOVA F-tests) assess the null hypothesis (e.g., that all group means are equal) by calculating a p-value. If the p-value is below a certain threshold (e.g., 0.05), the null hypothesis is rejected.\n",
    "b.The approach relies on fixed significance levels and often does not provide direct probabilities about hypotheses.\n",
    "Bayesian Approach:\n",
    "a.Bayesian hypothesis testing involves calculating the posterior probabilities of hypotheses. Instead of rejecting or failing to reject a null hypothesis, it assesses the strength of evidence for different hypotheses.\n",
    "b.The Bayesian framework can utilize Bayes factors to compare the relative evidence for competing hypotheses, allowing for a more nuanced interpretation of results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2701bc-5a01-41f9-a5b4-84b6b67272a1",
   "metadata": {},
   "source": [
    "8.You have two sets of data representing the incomes of two different professions \n",
    "Profession A: [48, 52, 55, 60, 62]\n",
    "Profession B: [45, 50, 55, 52, 47]\n",
    "Perform an F-test to determine if the variances of the two professions' incomes are equal. What are your conclusions based on the F-test?\n",
    "Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
    "Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29711aa1-6207-4a78-a109-933075bfaa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.089171974522293, 0.24652429950266952)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "profession_A = np.array([48, 52, 55, 60, 62])\n",
    "profession_B = np.array([45, 50, 55, 52, 47])\n",
    "\n",
    "var_A = np.var(profession_A, ddof=1)  # sample variance\n",
    "var_B = np.var(profession_B, ddof=1)  # sample variance\n",
    "\n",
    "F_statistic = var_A / var_B\n",
    "\n",
    "n_A = len(profession_A)\n",
    "n_B = len(profession_B)\n",
    "df_A = n_A - 1\n",
    "df_B = n_B - 1\n",
    "\n",
    "p_value = 1 - f.cdf(F_statistic, df_A, df_B)\n",
    "\n",
    "F_statistic, p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe2499-b0c9-43ab-8697-6a257156b53b",
   "metadata": {},
   "source": [
    "9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data\n",
    "Region A: [160, 162, 165, 158, 164]\n",
    "Region B: [172, 175, 170, 168, 174]\n",
    "Region C: [180, 182, 179, 185, 183]\n",
    "Task: Write Python code to perform the one-way ANOVA and interpret the results\n",
    "Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af5eafa-1ba4-4ead-843c-aa806e1b95da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67.87330316742101, 2.870664187937026e-07)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "region_A = np.array([160, 162, 165, 158, 164])\n",
    "region_B = np.array([172, 175, 170, 168, 174])\n",
    "region_C = np.array([180, 182, 179, 185, 183])\n",
    "\n",
    "F_statistic, p_value = f_oneway(region_A, region_B, region_C)\n",
    "\n",
    "F_statistic, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b0eba-6c02-4f35-b51c-29168b3e9e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
